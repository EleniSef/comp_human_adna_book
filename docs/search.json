[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Methods for human population genetics and ancient DNA",
    "section": "",
    "text": "Preface\nThis book summarises prepared mini-courses for various computational tools and methods in the field of human archaeogenetic data analysis, with a particular emphasis on population genetics.\nThe chapters are contributed by different authors, as indicated in the Yaml-frontmatter of each chapter’s .qmd source file."
  },
  {
    "objectID": "Quarto_intro.html#setting-up",
    "href": "Quarto_intro.html#setting-up",
    "title": "1  Introduction to Quarto",
    "section": "1.1 Setting up",
    "text": "1.1 Setting up\nQuarto is the “next generation” of R Markdown and is usable on different tools.\n\nHere, we will describe how to set up your environment to use Quarto in RStudio, and VSCode.\nQuarto in general is set up to be very intuitive and user friendly. And while it is possible to set up different documents simultaneously, those can also easily be set up to in just the way you need for whatever occasion. So, for either communicating your results to collaborators, discuss code with your supervisor, setting up a website or writing your paper, to just name some scenarios, quarto comes in quite handy. So, let’s begin:"
  },
  {
    "objectID": "Quarto_intro.html#rstudio",
    "href": "Quarto_intro.html#rstudio",
    "title": "1  Introduction to Quarto",
    "section": "1.2 RStudio",
    "text": "1.2 RStudio\nFor this, you have to download RStudio first. If you have done this already, we can get started.\n\n1.2.1 Getting started\nFirst, we have to install the quarto package using the following command in our console:\ninstall.packages(\"quarto\")\nNow we are ready to set up a quarto document.\nFor this we open a new project and select the quarto document we want to create. You can choose to set up a git repository as well. For practicality, I usually also tick the box visual markdown editor.\n\nThe new project will look like this:\n\n\n\n1.2.2 Universal instructions\nWhen setting up your document, quarto will always provide you with some presets. So first, we will have a look into the .qmd files, for they are handled the same way, regardless the format you are setting up (website, book, presentation, etc.).\n\n1.2.2.1 Render & save\nIf we now click on render, we will be provided with the preview of our final version if the project in the viewer.\nImportant: Do not mistake “save” with “render”. Just by saving, your document did not get rendered automatically, unless you tick the box “Render on Save”. You have to tick that box on each .qmd file individually though.\n\n\n\n1.2.2.2 Visual and Source\nIf you have chosen the Visual option on your toolbar, the preview will mostly resemble your .qmd files. If you are more comfortable with the R markdown optics, you can switch to Source.\nIn the Source version, you can write up your document in LaTeX.\n\n\n\n1.2.2.3 .qmd files\nQuarto will automatically provide you with two .qmd files, as well as a .yml file.\nThe .qmd files respond to the individual pages of your website or chapter of your book or pages of your presentation, etc. You can shape them individually or define the layout for all of them in the .yml file, to which we will get later.\nIn your .qmd files you also find a yaml at the top of your document, separated by\n---\n---\nWithin these, you can define the outline of .qmd file individually, starting with the page header. Other options, you might be using in the future are:\nauthor: Jessi Doe\n-&gt; will add an author underneath the header\nexecute:    echo: true\n-&gt; if &gt;true&lt;, code will be visible\ntoc:true\n-&gt; if &gt;true&lt;, a table of content will be automatically added\nbibliography: your_references.bib\n-&gt; file or list of files for your references\nIt is crucial to stick to the spacing. Otherwise, an error will occur.\n\n1.2.2.3.1 Insert\nIf you click Insert, you will realize, quarto provides you with a lot of options and shortcuts as well. So by just selecting on your chosen item to insert, it will be added to the document, while you are also provided with options on the appearance (in the case of figure/images or tables, etc). We will here have a brief look into how to work with R code and how to use the reference option.\n\n\n1.2.2.3.2 R code\nTo add R code to your file, you select Insert, select Code Cell and choose the kind of code you want to insert. In this case, R. There are some things to keep in mind though.\nDepending on how you have set up your .qmd file (or your .yml), your code will be visible or not on your website. To check your output, you can click the green arrow for the latest bit of code or the grey arrow above a bar to run the previous code.\n\nBut in case there are some chunks of code, you do not want to show all the time, there are some nice sets.\nSo if we just load the library tidyverse, for example, the additional information regardless and it will be also visible on our website.\n\nTo avoid this, we can set up a code chunk, looking like this:\n\nThis will prevent the output of this code chunk to be depicted on your website, while the package is otherwise active and can be used in the following R code. This is, by the way, true for all R code and data sets you will use: they will be active in your document and can be used in different code chunks, once provided.\nA code block included in your document could look like the following. Here I used the option\ncode-fold: true so the code can be extended. This option is only available in html though.\n\n\n\n1.2.2.3.3 References\nDepending on which citation program you are using, quarto is able to connect to it (Zotero works, for example). So, when selecting to insert a Citation, you can choose to simply add a reference from your program.\nAlternatively, you are provided with some options to choose from:\n\nIn your source code and your website, a citation will be depicted as follows:\n\nThe citation will also automatically be added to a references.bib as well as to a references.qmd and is therefore available on your website on the page “References”, which also will be created automatically.\n\n\n\n\n1.2.3 Render your document\nWhen done with setting up your documents, you would like to have the actual output. Depending on the format you set in your .yml file, your output can be a html, pdf, MS Word, OpenOffice, or ePUB file. To create those, the terminal in your RStudio Project is used.\nBy using the command:\nquarto render\nall formats you predefined in your .yml file will be rendered.\nIn case you are only interested in one format to be rendered, you can specify your command:\nquarto render -to pdf\nYour rendered document should now look like this:\n\n\n\n1.2.4 Quarto website\nIn the provided .qmd files, the index is also the first page of your website. As you might have noticed, quarto already sets up a navbar as well as a search function on your website.\n\n\n1.2.4.1 .yml files\nWhile your .qmd files contain information about one page, the .yml file defines the overall looks of the website.\nHere, you can define the type of your project (in this case a website), you can change the name of the website (Title), define your navbar (which shall be your landing page and in what order your pages shall be set up) or the overall appearance of your website in general (theme, css, toc, backgroundcolor, etc.). For different styles and layouts, check out the quarto website again.\n\n\n\n\n1.2.5 Quarto book\nThe setup of the .yml file in a quarto book is slightly different than that of the website. So here are some general remarks about them.\n\n1.2.5.1 .yml files\nWe see, for example, that instead of a navbar, we find chapters. Those will appear in the listed order in your book.\nWe also already get provided with a bibliography and the responding .bib file. If you have other .bib files, those can be included in your references, by just adding them to bibliography.\n\n_________________________________________________________________________\nWith this, you should at least have some ideas on how you can use quarto in your daily work routine. Happy coding and please feel free to contact me for any remarks or questions. I am happy to try and help."
  },
  {
    "objectID": "Quarto_intro.html#vscode",
    "href": "Quarto_intro.html#vscode",
    "title": "1  Introduction to Quarto",
    "section": "1.3 VSCode",
    "text": "1.3 VSCode\nMuch of the concepts as described in the RStudio tutorial above apply equally well to using Quarto in VSCode, just with a different interface to execute them.\nHere we will describe how to set up VSCode and Quarto, and how to preview and render Quarto objects within the VSCode interface.\nTo understand about more about the details of which files to edit etc., please see the RStudio description above.\n\n1.3.1 Getting Started\n\nInstall the Quarto CLI tool for your operating system from the Quarto Website\nInstall the VSCode Quarto extension\n\n\n\n1.3.2 Using Quarto\nThe basic workflow is as follows:\n\nCreate or modify .qmd objects etc as described above in the Rstudio section about Quarto markdown files\nWithin VSCode, make sure you’ve opened it in the repository containing all the files\nPress ctrl + shift + p to bring up your command palette\n\nTo preview a local ‘live’ version of HTML or website versions, you can type Quarto: preview. To close the live preview, press ctrl+c in the VSCode terminal.\nTo render all the files e.g. final HTML and/or PDF versions, you can type Quarto: Render Project, where you will be given different options depending on the formats defined in the _quarto.yml file.\n\n\nFor further VSCode integrations, just type Quarto: into your command palette and explore all the options."
  },
  {
    "objectID": "poseidon.html#the-components-of-poseidon",
    "href": "poseidon.html#the-components-of-poseidon",
    "title": "2  Genotype and context data management with Poseidon",
    "section": "2.1 The components of Poseidon",
    "text": "2.1 The components of Poseidon\n\n\n\nOverview of the Poseidon framework\n\n\nPoseidon is an entire ecosystem build on top of the data format specification of the Poseidon package.\n\n2.1.1 The Poseidon package\nA Poseidon package bundles genotype data in EIGENSTRAT/PLINK format with human- and machine-readable meta-data.\n\n\n\nThe files in a Poseidon package\n\n\nIt includes sample-wise context information like spatio-temporal origin and genetic data quality in the .janno-file, literature in the .bib, and pointers to sequencing data in the .ssf file.\n.janno and .ssf have many predefined and specified columns, but can store arbitrary additional variables.\n\n\n2.1.2 The software tools\ntrident is a command line application to create, download, inspect and merge Poseidon packages – and therefore the central tool of the Poseidon framework. The init subcommand creates new packages from genotype data, fetch downloads them from the public archives through the Web-API, and forge merges and subsets them as specified. list gives an overview over entities in a set of packages and validate confirms their structural integrity.\nxerxes is derived from trident and allows to directly perform various basic and experimental genomic data analyses on Poseidon packages. It implements allele sharing statistics (\\(F_2\\), \\(F_3\\), \\(F_4\\), \\(F_{ST}\\)) with a flexible permutation interface.\njanno is an R package to simplify reading .janno files into R and the popular tidyverse ecosystem (Wickham et al. (2019)). It provides an S3 class janno that inherits from tibble.\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\nqjanno is another command line tool to perform SQL queries on .janno files. On start-up it creates an SQLite database in memory and reads .janno files into it. It then sends any user-provided SQL query to the database server and forwards its output.\n\n\n2.1.3 The public archives\nThe Poseidon community maintains public archives for Poseidon packages to establish a central, open point of access for published, archaeogenetic genotype data.\n\nThe Community Archive: Author supplied, per-paper packages with the genotype data published in the respective papers. Partially pre-populated from various versions of the AADR.\nThe AADR Archive: Complete and structurally unified releases of the Allen Ancient DNA Resource (Mallick et al. (2023)) repackaged in the Poseidon package format.\nThe Minotaur Archive: Per-paper packages with genotype data reprocessed by the Minotaur workflow (see below).\n\n\nMallick, Swapan, Adam Micco, Matthew Mah, Harald Ringbauer, Iosif Lazaridis, Iñigo Olalde, Nick Patterson, and David Reich. 2023. “The Allen Ancient DNA Resource (AADR): A Curated Compendium of Ancient Human Genomes,” April. https://doi.org/10.1101/2023.04.06.535797.\nThe data is versioned with Git and hosted on GitHub for easy co-editing and automatic structural validation.\nIt can be accessed through a Web-API with various endpoints at server.poseidon-adna.org, e.g. /packages for a JSON list of packages in the community archive.\nThis API enables a little Archive explorer web app on the Poseidon website.\n\n\n2.1.4 The Minotaur workflow\nThe Minotaur workflow is a semi-automatic workflow to reproducibly process published sequencing data from the International Nucleotide Sequence Database Collaboration (INSDC) archives into Poseidon packages.\nCommunity members can request new packages by submitting a build recipe as a Pull Request against a dedicated submission GitHub repository. This recipe is derived from a Sequencing Source File (.ssf), describing the sequencing data for the package and where it can be downloaded.\nUsing the recipe, the sequencing data gets processed through nf-core/eager (Yates et al. (2021)) on computational infrastructure of MPI-EVA, using a standardised, yet flexible, set of parameters.\n\nYates, James A. Fellows, Thiseas C. Lamnidis, Maxime Borry, Aida Andrades Valtueña, Zandra Fagernäs, Stephen Clayton, Maxime U. Garcia, Judith Neukamm, and Alexander Peltzer. 2021. “Reproducible, Portable, and Efficient Ancient Genome Reconstruction with Nf-Core/Eager.” PeerJ 9 (March): e10947. https://doi.org/10.7717/peerj.10947.\nThe generated genotypes, together with descriptive statistics of the sequencing data (Endogenous, Damage, Nr_SNPs, Contamination), are compiled into a Poseidon package, and made available to users in the Minotaur archive."
  },
  {
    "objectID": "poseidon.html#forging-a-dataset-with-trident",
    "href": "poseidon.html#forging-a-dataset-with-trident",
    "title": "2  Genotype and context data management with Poseidon",
    "section": "2.2 Forging a dataset with trident",
    "text": "2.2 Forging a dataset with trident\nforge creates new Poseidon packages by extracting and merging packages, populations and individuals/samples from your Poseidon repositories. It can also work directly with your genotype data. In addition, forge allows merging of multiple data sets (packages), in contrast to mergeit which merges only two data sets at a time.\n(-f/--forgeString) can be used to query entire packages, groups or individuals. In general --forgeString query consists of multiple entities, inside \"\" separated by , .\n\nTo include all individuals in a Poseidon package, use * to surround the package title.*2019_Jeong_InnerEurasia* . In cases where only genotype files are available, use the file name prefix.\nTo include certain group(s) from a Poseidon package, simply add them to the -f query. No specific markers are required. Russia_HG_Karelia\nTo extract individuals only, surround them by &lt; and &gt;. &lt;ALA026&gt; . To exclude individuals add package name *package* and &lt;individual&gt; with a dash sign. \"*2021_Saag_EastEuropean-3.2.0*,-&lt;NIK003&gt;\"\n\n\ntrident forge \\\n  -p pileupcaller.double.geno \\\n  -d 2021_Saag_EastEuropean-3.2.0 \\\n  -d 2016_FuNature-2.1.1 \\\n  -f \"*pileupcaller.double*,Russia_AfontovaGora3,&lt;NIK003&gt;\" \\\n  -o testpackage \\\n  --outFormat EIGENSTRAT \\\n  /\nForge selection language\nforge has a an optional flag --intersect, that defines, if the genotype data from different packages should be merged with an intersect instead of the default union operation. The default is to output the union of all SNPs, by setting the additional SNPs from the other merged package as missing in the samples that did not have them originally. This option is useful for making a data set based on Human Origins (HO) SNPs for analysis like PCA and ADMIXTURE.\ntrident forge \\\n  --intersect \\\n  -p pileupcaller.double.geno \\\n  -d 2012_PattersonGenetics-2.1.3 \\\n  -o testpackage_HO \\\n  --outFormat EIGENSTRAT \\\n  /\nIn case of PCA, --forgeFile can be used to merge necessary populations/groups from the available packages in the community archive to create specific PCA configurations.\ntrident forge \\\n  -d /path/to/community/archive \\\n  --forgeFile WestEurasia_poplist.txt \\\n  -o WE_PCA \\\n  /\nIn addition, --selectSnps allows to provide forge with a SNP file in EIGENSTRAT (.snp) or PLINK (.bim) format to create a package with a specific selection. This option generates a package with exactly the SNPs listed in this file."
  },
  {
    "objectID": "poseidon.html#contributing-to-the-community-archive",
    "href": "poseidon.html#contributing-to-the-community-archive",
    "title": "2  Genotype and context data management with Poseidon",
    "section": "2.3 Contributing to the community archive",
    "text": "2.3 Contributing to the community archive\n\n\n\nPoseidon needs your data as soon as it is published\n\n\nTo maintain the public data archives, specifically the community archive and the minotaur archive, Poseidon depends on work donations by an interested community.\nMany practitioners of archaeogenetics both produce genotype data from archaological contexts and require the reference data from other publications, provided in public archives, to contextualize it.\nIf authors themselves provide high-quality, easily accessible versions of their data beyond the raw data available at the INSDC databases, they gain at least three important advantages:\n\nTheir work will be easily findable and potentially cited more often.\nThey have primacy over how their data is communicated. That is, which genotypes, dates or group names they consider correct.\nTheir results for derived, genotype based analyses (PCA, F-Statistics, etc.) can be reproduced exactly.\n\nAnd the whole community wins, because sharing the tedious data preparation tasks empowers all researchers to achieve more in shorter time.\n\n\n\n\nThis tutorial explains the main cornerstones of a workflow to add a new Poseidon package to the community archive after publishing the corresponding dataset. The process is documented in more detail in a Submission guide on the website.\n\nMake yourself familiar with a number of core technologies. This is less daunting than it sounds, because: Superficial knowledge is sufficient and knowing them is useful beyond this particular task.\n\n\nCreating and validating Poseidon packages with the trident tool.\nFree and open source distributed version control with Git.\nCollaborative working on Git projects with GitHub.\nHandling large files in Git using Git LFS.\n\n\nCreate a package from your genotype data and fill it with a suitable set of meta and context information.\n\n\ntrident init allows to wrap genotype data in a dummy Poseidon package. Imagine we had genotype data for a number of individuals in EIGENSTRAT format:\n\n\nmyData.ind\n\nSample1  M       ExamplePop1\nSample2  F       ExamplePop1\nSample3  M       ExamplePop2\n\n\n\nmyData.snp\n\n           rs3094315     1        0.020130          752566 G A\n          rs12124819     1        0.020242          776546 A G\n          rs28765502     1        0.022137          832918 T C\n\n\n\nmyData.geno\n\n099\n922\n999\n\nWith trident init -p myData.geno -o myPackage we can create a basic package around this data.\n$ ls myPackage\nmyData.geno  myData.snp     myPackage.janno\nmyData.ind   myPackage.bib  POSEIDON.yml\nIn a next step we modify POSEIDON.yml, .janno and .bib to include the context information we consider relevant. All of these files are well specified and documented, so we only demonstrate a minimal change for this example:\nWe replace the main contributor for the package.\n\n\nmyPackage/POSEIDON.yml\n\nposeidonVersion: 2.7.1\ntitle: myPackage\ndescription: Empty package template. Please add a description\ncontributor:\n- name: Clemens Schmid               #- name: Josiah Carberry\n  email: clemens_schmid@eva.mpg.de   #  email: carberry@brown.edu\n  orcid: 0000-0003-3448-5715         #  orcid: 0000-0002-1825-0097\npackageVersion: 0.1.0\nlastModified: 2023-10-18\ngenotypeData:\n  format: EIGENSTRAT\n  genoFile: myData.geno\n  snpFile: myData.snp\n  indFile: myData.ind\n  snpSet: Other\njannoFile: myPackage.janno\nbibFile: myPackage.bib\n\nWhen we applied all necessary modifications we can confirm that the package is still valid with trident validate -d myPackage.\n\n\nSubmit the package to the community archive.\n\n\nTo submit the package we have to create a fork of the community archive repository on GitHub. This requires a GitHub account.\n\n\n\n\nPress the fork button in the top right corner to fork a repository on GitHub\n\n\n\nAnd then clone the fork to our computer, while omitting the large genotype data files. Note that this requires several setup steps to work correctly:\n\nGit has be installed for your computer (see here)\nYou must have created an ssh key pair to connect to GitHub via ssh (see here)\nGit LFS has to be installed (see here) and and configured for your user with git lfs install\n\nGIT_LFS_SKIP_SMUDGE=1 git clone git@github.com:&lt;yourGitHubUserName&gt;/community-archive.git\nWith the cloned repository on our system we can copy the files into the repositories directory and commit the changes.\n\n\nin the community-archive directory\n\ncp -r ../myPackage myPackage\ngit add myPackage\ngit commit -m \"added a first draft of myPackage\"\ngit push\n\nIn a last step we can open a Pull Request on GitHub from our fork to the original archive repository. Poseidon core members will take it from here.\n\n\n\n\nWhen you pushed to your fork, GitHub will automatically offer to “contribute” to the source repository"
  },
  {
    "objectID": "fstats.html",
    "href": "fstats.html",
    "title": "3  Introduction to F-Statistics",
    "section": "",
    "text": "4 Introduction\nF-Statistics are one of the simplest summary-statistics of genotype data that help us gain insights into the relationships of individuals and groups.\nSome key references up front:\nOutgroup-F3-Statistics are perhaps one of the easiest to understand, so we’ll start with them. F3-Statistics in general are defined as:\n\\[F_3(A, B;C) = \\langle(c-a)(c-b)\\rangle\\]\nwhich looks a bit unintuitive. Here, \\(A\\) and \\(B\\) are populations or individuals to be compared, and \\(C\\) denotes an outgroup, and \\(a\\) and \\(b\\) are the non-reference allele frequencies of \\(A\\) and \\(B\\), respectively. The expression \\(\\langle\\cdot\\rangle\\) denotes an average over all SNPs in the dataset.\nWe can understand it best as a measure of genetic similarity between groups A and B, evaluated on SNPs where A and B carry a different allele than the outgroup C. Here is an example based on A, B and C all consisting of just a single haploid sample each:\nEvery SNP where A and B have the same allele, which in turn is different from the outgroup C contributes 1 to the statistic, all other positions contribute 0. So the higher this number, the more similar A and B are, and the more distant is the outgroup C from both A and B."
  },
  {
    "objectID": "fstats.html#linearity-in-a-and-b-but-not-c",
    "href": "fstats.html#linearity-in-a-and-b-but-not-c",
    "title": "3  Introduction to F-Statistics",
    "section": "5.1 Linearity in A and B (but not C)",
    "text": "5.1 Linearity in A and B (but not C)\nWhat happens if \\(A\\) and \\(B\\) are populations, instead of single samples? Conveniently, this statistic is linear in A and B, which means that the resulting statistic will just be an average over all combinations of individuals in A and B. The same is true for diploid samples A and B, in which case the result will just be the average similarity between all haplotypes between A and B. In mathematical terms:\n\\[F_3(\\{A_1,A_2\\},B;C) = \\frac{1}{2}(F_3(A_1,B;C)+F_3(A_2,B;C))\\]\n(and similarly for $B={B_1,B_2}).\nNote that F_3 statistics are not linear in \\(C\\). This has rarely any consequences, because we typically use some fixed group for \\(C\\) (see below0), and only vary \\(A\\) and \\(B\\) in our analyses. But it is useful for the interpration to know that at least for A and B, group-based statistics are simply averages over individual-based ones."
  },
  {
    "objectID": "fstats.html#how-to-use-outgroup-f3",
    "href": "fstats.html#how-to-use-outgroup-f3",
    "title": "3  Introduction to F-Statistics",
    "section": "5.2 How to use Outgroup-F3",
    "text": "5.2 How to use Outgroup-F3\nOutgroup-F3 are most commonly used to characterize an individual or population of interest by its relationship to a set of reference populations, for example to reveal geographic or cultural patterns of similarity.\nAn example is this Figure from (Raghavan et al. 2014):\n\n\n\n\nPatterson, Nick, Priya Moorjani, Yontao Luo, Swapan Mallick, Nadin Rohland, Yiping Zhan, Teri Genschoreck, Teresa Webster, and David Reich. 2012. “Ancient Admixture in Human History.” Genetics 192 (3): 1065–93. https://doi.org/10.1534/genetics.112.145037.\n\n\nPeter, Benjamin M. 2016. “Admixture, Population Structure, and F-Statistics.” Genetics 202 (4): 1485–1501. https://doi.org/10.1534/genetics.115.183913.\n\n\nRaghavan, Maanasa, Pontus Skoglund, Kelly E Graf, Mait Metspalu, Anders Albrechtsen, Ida Moltke, Simon Rasmussen, et al. 2014. “Upper Palaeolithic Siberian Genome Reveals Dual Ancestry of Native Americans.” Nature 505 (7481): 87–91. https://doi.org/10.1038/nature12736."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Mallick, Swapan, Adam Micco, Matthew Mah, Harald Ringbauer, Iosif\nLazaridis, Iñigo Olalde, Nick Patterson, and David Reich. 2023.\n“The Allen Ancient DNA Resource (AADR):\nA Curated Compendium of Ancient Human Genomes,” April. https://doi.org/10.1101/2023.04.06.535797.\n\n\nPatterson, Nick, Priya Moorjani, Yontao Luo, Swapan Mallick, Nadin\nRohland, Yiping Zhan, Teri Genschoreck, Teresa Webster, and David Reich.\n2012. “Ancient Admixture in Human History.”\nGenetics 192 (3): 1065–93. https://doi.org/10.1534/genetics.112.145037.\n\n\nPeter, Benjamin M. 2016. “Admixture, Population Structure, and\nF-Statistics.” Genetics 202 (4): 1485–1501.\nhttps://doi.org/10.1534/genetics.115.183913.\n\n\nRaghavan, Maanasa, Pontus Skoglund, Kelly E Graf, Mait Metspalu, Anders\nAlbrechtsen, Ida Moltke, Simon Rasmussen, et al. 2014. “Upper\nPalaeolithic Siberian Genome Reveals Dual Ancestry of Native\nAmericans.” Nature 505 (7481): 87–91. https://doi.org/10.1038/nature12736.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg,\nGabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al.\n2016. “The FAIR Guiding Principles for Scientific\nData Management and Stewardship.” Scientific Data 3 (1).\nhttps://doi.org/10.1038/sdata.2016.18.\n\n\nYates, James A. Fellows, Thiseas C. Lamnidis, Maxime Borry, Aida\nAndrades Valtueña, Zandra Fagernäs, Stephen Clayton, Maxime U. Garcia,\nJudith Neukamm, and Alexander Peltzer. 2021. “Reproducible,\nPortable, and Efficient Ancient Genome Reconstruction with\nNf-Core/Eager.” PeerJ 9 (March): e10947. https://doi.org/10.7717/peerj.10947."
  }
]