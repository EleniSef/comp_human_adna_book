[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Methods for human population genetics and ancient DNA",
    "section": "",
    "text": "This book summarises prepared mini-courses for various computational tools and methods in the field of human archaeogenetic data analysis, with a particular emphasis on population genetics.\nThe chapters are contributed by different authors, as indicated in the Yaml-frontmatter of each chapter’s .qmd source file."
  },
  {
    "objectID": "Quarto_intro.html",
    "href": "Quarto_intro.html",
    "title": "1  Introduction to Quarto",
    "section": "",
    "text": "In this introduction to quarto, you will be shown the basics in how to set up a website and a book. For more detailed information, I highly recommend checking out the website and also watch the introduction tutorial."
  },
  {
    "objectID": "Quarto_intro.html#setting-up",
    "href": "Quarto_intro.html#setting-up",
    "title": "1  Introduction to Quarto",
    "section": "1.1 Setting up",
    "text": "1.1 Setting up\nQuarto is the “next generation” of R Markdown and is usable on different tools.\n\nHere, we will describe how to set up your environment to use Quarto in RStudio, and VSCode.\nQuarto in general is set up to be very intuitive and user friendly. And while it is possible to set up different documents simultaneously, those can also easily be set up to in just the way you need for whatever occasion. So, for either communicating your results to collaborators, discuss code with your supervisor, setting up a website or writing your paper, to just name some scenarios, quarto comes in quite handy. So, let’s begin:"
  },
  {
    "objectID": "Quarto_intro.html#rstudio",
    "href": "Quarto_intro.html#rstudio",
    "title": "1  Introduction to Quarto",
    "section": "1.2 RStudio",
    "text": "1.2 RStudio\nFor this, you have to download RStudio first. If you have done this already, we can get started.\n\n1.2.1 Getting started\nFirst, we have to install the quarto package using the following command in our console:\ninstall.packages(\"quarto\")\nNow we are ready to set up a quarto document.\nFor this we open a new project and select the quarto document we want to create. You can choose to set up a git repository as well. For practicality, I usually also tick the box visual markdown editor.\n\nThe new project will look like this:\n\n\n\n1.2.2 Universal instructions\nWhen setting up your document, quarto will always provide you with some presets. So first, we will have a look into the .qmd files, for they are handled the same way, regardless the format you are setting up (website, book, presentation, etc.).\n\n1.2.2.1 Render & save\nIf we now click on render, we will be provided with the preview of our final version if the project in the viewer.\nImportant: Do not mistake “save” with “render”. Just by saving, your document did not get rendered automatically, unless you tick the box “Render on Save”. You have to tick that box on each .qmd file individually though.\n\n\n\n1.2.2.2 Visual and Source\nIf you have chosen the Visual option on your toolbar, the preview will mostly resemble your .qmd files. If you are more comfortable with the R markdown optics, you can switch to Source.\nIn the Source version, you can write up your document in LaTeX.\n\n\n\n1.2.2.3 .qmd files\nQuarto will automatically provide you with two .qmd files, as well as a .yml file.\nThe .qmd files respond to the individual pages of your website or chapter of your book or pages of your presentation, etc. You can shape them individually or define the layout for all of them in the .yml file, to which we will get later.\nIn your .qmd files you also find a yaml at the top of your document, separated by\n---\n---\nWithin these, you can define the outline of .qmd file individually, starting with the page header. Other options, you might be using in the future are:\nauthor: Jessi Doe\n-> will add an author underneath the header\nexecute:    echo: true\n-> if >true<, code will be visible\ntoc:true\n-> if >true<, a table of content will be automatically added\nbibliography: your_references.bib\n-> file or list of files for your references\nIt is crucial to stick to the spacing. Otherwise, an error will occur.\n\n1.2.2.3.1 Insert\nIf you click Insert, you will realize, quarto provides you with a lot of options and shortcuts as well. So by just selecting on your chosen item to insert, it will be added to the document, while you are also provided with options on the appearance (in the case of figure/images or tables, etc). We will here have a brief look into how to work with R code and how to use the reference option.\n\n\n1.2.2.3.2 R code\nTo add R code to your file, you select Insert, select Code Cell and choose the kind of code you want to insert. In this case, R. There are some things to keep in mind though.\nDepending on how you have set up your .qmd file (or your .yml), your code will be visible or not on your website. To check your output, you can click the green arrow for the latest bit of code or the grey arrow above a bar to run the previous code.\n\nBut in case there are some chunks of code, you do not want to show all the time, there are some nice sets.\nSo if we just load the library tidyverse, for example, the additional information regardless and it will be also visible on our website.\n\nTo avoid this, we can set up a code chunk, looking like this:\n\nThis will prevent the output of this code chunk to be depicted on your website, while the package is otherwise active and can be used in the following R code. This is, by the way, true for all R code and data sets you will use: they will be active in your document and can be used in different code chunks, once provided.\nA code block included in your document could look like the following. Here I used the option\ncode-fold: true so the code can be extended. This option is only available in html though.\n\n\n\n1.2.2.3.3 References\nDepending on which citation program you are using, quarto is able to connect to it (Zotero works, for example). So, when selecting to insert a Citation, you can choose to simply add a reference from your program.\nAlternatively, you are provided with some options to choose from:\n\nIn your source code and your website, a citation will be depicted as follows:\n\nThe citation will also automatically be added to a references.bib as well as to a references.qmd and is therefore available on your website on the page “References”, which also will be created automatically.\n\n\n\n\n1.2.3 Render your document\nWhen done with setting up your documents, you would like to have the actual output. Depending on the format you set in your .yml file, your output can be a html, pdf, MS Word, OpenOffice, or ePUB file. To create those, the terminal in your RStudio Project is used.\nBy using the command:\nquarto render\nall formats you predefined in your .yml file will be rendered.\nIn case you are only interested in one format to be rendered, you can specify your command:\nquarto render -to pdf\nYour rendered document should now look like this:\n\n\n\n1.2.4 Quarto website\nIn the provided .qmd files, the index is also the first page of your website. As you might have noticed, quarto already sets up a navbar as well as a search function on your website.\n\n\n1.2.4.1 .yml files\nWhile your .qmd files contain information about one page, the .yml file defines the overall looks of the website.\nHere, you can define the type of your project (in this case a website), you can change the name of the website (Title), define your navbar (which shall be your landing page and in what order your pages shall be set up) or the overall appearance of your website in general (theme, css, toc, backgroundcolor, etc.). For different styles and layouts, check out the quarto website again.\n\n\n\n\n1.2.5 Quarto book\nThe setup of the .yml file in a quarto book is slightly different than that of the website. So here are some general remarks about them.\n\n1.2.5.1 .yml files\nWe see, for example, that instead of a navbar, we find chapters. Those will appear in the listed order in your book.\nWe also already get provided with a bibliography and the responding .bib file. If you have other .bib files, those can be included in your references, by just adding them to bibliography.\n\n_________________________________________________________________________\nWith this, you should at least have some ideas on how you can use quarto in your daily work routine. Happy coding and please feel free to contact me for any remarks or questions. I am happy to try and help."
  },
  {
    "objectID": "Quarto_intro.html#vscode",
    "href": "Quarto_intro.html#vscode",
    "title": "1  Introduction to Quarto",
    "section": "1.3 VSCode",
    "text": "1.3 VSCode\nMuch of the concepts as described in the RStudio tutorial above apply equally well to using Quarto in VSCode, just with a different interface to execute them.\nHere we will describe how to set up VSCode and Quarto, and how to preview and render Quarto objects within the VSCode interface.\nTo understand about more about the details of which files to edit etc., please see the RStudio description above.\n\n1.3.1 Getting Started\n\nInstall the Quarto CLI tool for your operating system from the Quarto Website\nInstall the VSCode Quarto extension\n\n\n\n1.3.2 Using Quarto\nThe basic workflow is as follows:\n\nCreate or modify .qmd objects etc as described above in the Rstudio section about Quarto markdown files\nWithin VSCode, make sure you’ve opened it in the repository containing all the files\nPress ctrl + shift + p to bring up your command palette\n\nTo preview a local ‘live’ version of HTML or website versions, you can type Quarto: preview. To close the live preview, press ctrl+c in the VSCode terminal.\nTo render all the files e.g. final HTML and/or PDF versions, you can type Quarto: Render Project, where you will be given different options depending on the formats defined in the _quarto.yml file.\n\n\nFor further VSCode integrations, just type Quarto: into your command palette and explore all the options."
  },
  {
    "objectID": "poseidon.html",
    "href": "poseidon.html",
    "title": "2  Genotype and context data management with Poseidon",
    "section": "",
    "text": "Poseidon is an open computational framework to enable standardised and FAIR (Wilkinson et al. (2016)) handling of genotypes with their highly relevant context information.\nIt includes a well-specified data format, advanced software tools, and public, community-maintained archives to support the entire archaeogenetic research cycle, from data acquisition to management, analysis and publication.\nPoseidon and all its components is well documented at https://www.poseidon-adna.org. In this tutorial we will give a brief overview and highlight two workflows in the context of Poseidon."
  },
  {
    "objectID": "poseidon.html#the-components-of-poseidon",
    "href": "poseidon.html#the-components-of-poseidon",
    "title": "2  Genotype and context data management with Poseidon",
    "section": "2.1 The components of Poseidon",
    "text": "2.1 The components of Poseidon\n\n\n\nOverview of the Poseidon framework\n\n\nPoseidon is an entire ecosystem build on top of the data format specification of the Poseidon package.\n\n2.1.1 The Poseidon package\nA Poseidon package bundles genotype data in EIGENSTRAT/PLINK format with human- and machine-readable meta-data.\n\n\n\nThe files in a Poseidon package\n\n\nIt includes sample-wise context information like spatio-temporal origin and genetic data quality in the .janno-file, literature in the .bib, and pointers to sequencing data in the .ssf file.\n.janno and .ssf have many predefined and specified columns, but can store arbitrary additional variables.\n\n\n2.1.2 The software tools\ntrident is a command line application to create, download, inspect and merge Poseidon packages – and therefore the central tool of the Poseidon framework. The init subcommand creates new packages from genotype data, fetch downloads them from the public archives through the Web-API, and forge merges and subsets them as specified. list gives an overview over entities in a set of packages and validate confirms their structural integrity.\nxerxes is derived from trident and allows to directly perform various basic and experimental genomic data analyses on Poseidon packages. It implements allele sharing statistics (\\(F_2\\), \\(F_3\\), \\(F_4\\), \\(F_{ST}\\)) with a flexible permutation interface.\njanno is an R package to simplify reading .janno files into R and the popular tidyverse ecosystem (Wickham et al. (2019)). It provides an S3 class janno that inherits from tibble.\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\nqjanno is another command line tool to perform SQL queries on .janno files. On start-up it creates an SQLite database in memory and reads .janno files into it. It then sends any user-provided SQL query to the database server and forwards its output.\n\n\n2.1.3 The public archives\nThe Poseidon community maintains public archives for Poseidon packages to establish a central, open point of access for published, archaeogenetic genotype data.\n\nThe Community Archive: Author supplied, per-paper packages with the genotype data published in the respective papers. Partially pre-populated from various versions of the AADR.\nThe AADR Archive: Complete and structurally unified releases of the Allen Ancient DNA Resource (Mallick et al. (2023)) repackaged in the Poseidon package format.\nThe Minotaur Archive: Per-paper packages with genotype data reprocessed by the Minotaur workflow (see below).\n\n\nMallick, Swapan, Adam Micco, Matthew Mah, Harald Ringbauer, Iosif Lazaridis, Iñigo Olalde, Nick Patterson, and David Reich. 2023. “The Allen Ancient DNA Resource (AADR): A Curated Compendium of Ancient Human Genomes,” April. https://doi.org/10.1101/2023.04.06.535797.\nThe data is versioned with Git and hosted on GitHub for easy co-editing and automatic structural validation.\nIt can be accessed through a Web-API with various endpoints at server.poseidon-adna.org, e.g. /packages for a JSON list of packages in the community archive.\nThis API enables a little Archive explorer web app on the Poseidon website.\n\n\n2.1.4 The Minotaur workflow\nThe Minotaur workflow is a semi-automatic workflow to reproducibly process published sequencing data from the International Nucleotide Sequence Database Collaboration (INSDC) archives into Poseidon packages.\nCommunity members can request new packages by submitting a build recipe as a Pull Request against a dedicated submission GitHub repository. This recipe is derived from a Sequencing Source File (.ssf), describing the sequencing data for the package and where it can be downloaded.\nUsing the recipe, the sequencing data gets processed through nf-core/eager (Fellows Yates et al. (2021)) on computational infrastructure of MPI-EVA, using a standardised, yet flexible, set of parameters.\n\nFellows Yates, James A., Thiseas C. Lamnidis, Maxime Borry, Aida Andrades Valtueña, Zandra Fagernäs, Stephen Clayton, Maxime U. Garcia, Judith Neukamm, and Alexander Peltzer. 2021. “Reproducible, Portable, and Efficient Ancient Genome Reconstruction with Nf-Core/Eager.” PeerJ 9 (March): e10947. https://doi.org/10.7717/peerj.10947.\nThe generated genotypes, together with descriptive statistics of the sequencing data (Endogenous, Damage, Nr_SNPs, Contamination), are compiled into a Poseidon package, and made available to users in the Minotaur archive."
  },
  {
    "objectID": "poseidon.html#forging-a-dataset-with-trident",
    "href": "poseidon.html#forging-a-dataset-with-trident",
    "title": "2  Genotype and context data management with Poseidon",
    "section": "2.2 Forging a dataset with trident",
    "text": "2.2 Forging a dataset with trident\nforge creates new Poseidon packages by extracting and merging packages, populations and individuals/samples from your Poseidon repositories. It can also work directly with your genotype data. In addition, forge allows merging of multiple data sets (packages), in contrast to mergeit which merges only two data sets at a time.\n(-f/--forgeString) can be used to query entire packages, groups or individuals. In general --forgeString query consists of multiple entities, inside \"\" separated by , .\n\nTo include all individuals in a Poseidon package, use * to surround the package title.*2019_Jeong_InnerEurasia* . In cases where only genotype files are available, use the file name prefix.\nTo include certain group(s) from a Poseidon package, simply add them to the -f query. No specific markers are required. Russia_HG_Karelia\nTo extract individuals only, surround them by < and >. <ALA026> . To exclude individuals add package name *package* and <individual> with a dash sign. \"*2021_Saag_EastEuropean-3.2.0*,-<NIK003>\"\n\n\ntrident forge \\\n  -p pileupcaller.double.geno \\\n  -d 2021_Saag_EastEuropean-3.2.0 \\\n  -d 2016_FuNature-2.1.1 \\\n  -f \"*pileupcaller.double*,Russia_AfontovaGora3,<NIK003>\" \\\n  -o testpackage \\\n  --outFormat EIGENSTRAT \\\n  /\nForge selection language\nforge has a an optional flag --intersect, that defines, if the genotype data from different packages should be merged with an intersect instead of the default union operation. The default is to output the union of all SNPs, by setting the additional SNPs from the other merged package as missing in the samples that did not have them originally. This option is useful for making a data set based on Human Origins (HO) SNPs for analysis like PCA and ADMIXTURE.\ntrident forge \\\n  --intersect \\\n  -p pileupcaller.double.geno \\\n  -d 2012_PattersonGenetics-2.1.3 \\\n  -o testpackage_HO \\\n  --outFormat EIGENSTRAT \\\n  /\nIn case of PCA, --forgeFile can be used to merge necessary populations/groups from the available packages in the community archive to create specific PCA configurations.\ntrident forge \\\n  -d /path/to/community/archive \\\n  --forgeFile WestEurasia_poplist.txt \\\n  -o WE_PCA \\\n  /\nIn addition, --selectSnps allows to provide forge with a SNP file in EIGENSTRAT (.snp) or PLINK (.bim) format to create a package with a specific selection. This option generates a package with exactly the SNPs listed in this file."
  },
  {
    "objectID": "poseidon.html#contributing-to-the-community-archive",
    "href": "poseidon.html#contributing-to-the-community-archive",
    "title": "2  Genotype and context data management with Poseidon",
    "section": "2.3 Contributing to the community archive",
    "text": "2.3 Contributing to the community archive\n\n\n\nPoseidon needs your data as soon as it is published\n\n\nTo maintain the public data archives, specifically the community archive and the minotaur archive, Poseidon depends on work donations by an interested community.\nMany practitioners of archaeogenetics both produce genotype data from archaological contexts and require the reference data from other publications, provided in public archives, to contextualize it.\nIf authors themselves provide high-quality, easily accessible versions of their data beyond the raw data available at the INSDC databases, they gain at least three important advantages:\n\nTheir work will be easily findable and potentially cited more often.\nThey have primacy over how their data is communicated. That is, which genotypes, dates or group names they consider correct.\nTheir results for derived, genotype based analyses (PCA, F-Statistics, etc.) can be reproduced exactly.\n\nAnd the whole community wins, because sharing the tedious data preparation tasks empowers all researchers to achieve more in shorter time.\n\n\n\n\nThis tutorial explains the main cornerstones of a workflow to add a new Poseidon package to the community archive after publishing the corresponding dataset. The process is documented in more detail in a Submission guide on the website.\n\nMake yourself familiar with a number of core technologies. This is less daunting than it sounds, because: Superficial knowledge is sufficient and knowing them is useful beyond this particular task.\n\n\nCreating and validating Poseidon packages with the trident tool.\nFree and open source distributed version control with Git.\nCollaborative working on Git projects with GitHub.\nHandling large files in Git using Git LFS.\n\n\nCreate a package from your genotype data and fill it with a suitable set of meta and context information.\n\n\ntrident init allows to wrap genotype data in a dummy Poseidon package. Imagine we had genotype data for a number of individuals in EIGENSTRAT format:\n\n\nmyData.ind\n\nSample1  M       ExamplePop1\nSample2  F       ExamplePop1\nSample3  M       ExamplePop2\n\n\n\nmyData.snp\n\n           rs3094315     1        0.020130          752566 G A\n          rs12124819     1        0.020242          776546 A G\n          rs28765502     1        0.022137          832918 T C\n\n\n\nmyData.geno\n\n099\n922\n999\n\nWith trident init -p myData.geno -o myPackage we can create a basic package around this data.\n$ ls myPackage\nmyData.geno  myData.snp     myPackage.janno\nmyData.ind   myPackage.bib  POSEIDON.yml\nIn a next step we modify POSEIDON.yml, .janno and .bib to include the context information we consider relevant. All of these files are well specified and documented, so we only demonstrate a minimal change for this example:\nWe replace the main contributor for the package.\n\n\nmyPackage/POSEIDON.yml\n\nposeidonVersion: 2.7.1\ntitle: myPackage\ndescription: Empty package template. Please add a description\ncontributor:\n- name: Clemens Schmid               #- name: Josiah Carberry\n  email: clemens_schmid@eva.mpg.de   #  email: carberry@brown.edu\n  orcid: 0000-0003-3448-5715         #  orcid: 0000-0002-1825-0097\npackageVersion: 0.1.0\nlastModified: 2023-10-18\ngenotypeData:\n  format: EIGENSTRAT\n  genoFile: myData.geno\n  snpFile: myData.snp\n  indFile: myData.ind\n  snpSet: Other\njannoFile: myPackage.janno\nbibFile: myPackage.bib\n\nWhen we applied all necessary modifications we can confirm that the package is still valid with trident validate -d myPackage.\n\n\nSubmit the package to the community archive.\n\n\nTo submit the package we have to create a fork of the community archive repository on GitHub. This requires a GitHub account.\n\n\n\n\nPress the fork button in the top right corner to fork a repository on GitHub\n\n\n\nAnd then clone the fork to our computer, while omitting the large genotype data files. Note that this requires several setup steps to work correctly:\n\nGit has be installed for your computer (see here)\nYou must have created an ssh key pair to connect to GitHub via ssh (see here)\nGit LFS has to be installed (see here) and and configured for your user with git lfs install\n\nGIT_LFS_SKIP_SMUDGE=1 git clone git@github.com:<yourGitHubUserName>/community-archive.git\nWith the cloned repository on our system we can copy the files into the repositories directory and commit the changes.\n\n\nin the community-archive directory\n\ncp -r ../myPackage myPackage\ngit add myPackage\ngit commit -m \"added a first draft of myPackage\"\ngit push\n\nIn a last step we can open a Pull Request on GitHub from our fork to the original archive repository. Poseidon core members will take it from here.\n\n\n\n\nWhen you pushed to your fork, GitHub will automatically offer to “contribute” to the source repository"
  },
  {
    "objectID": "fstats.html",
    "href": "fstats.html",
    "title": "3  Introduction to F3- and F4-Statistics",
    "section": "",
    "text": "F3 statistics are a useful analytical tool to understand population relationships. F3 statistics, just as F4 and F2 statistics measure allele frequency correlations between populations and were introduced by Nick Patterson (Patterson et al. 2012), but see also (Peter 2016) for another introduction.\nF3 statistics are used for two purposes: i) as a test whether a target population (C) is admixed between two source populations (A and B), and ii) to measure shared drift between two test populations (A and B) from an outgroup (C).\nF3 statistics are in both cases defined as the product of allele frequency differences between population C to A and B, respectively:\n\\[F3(A,B;C)=\\langle(c−a)(c−b)\\rangle\\]\nHere, \\(\\langle\\cdot\\rangle\\) denotes the average over all genotyped sites, and a, b and c denote the allele frequency for a given site in the three populations A, B and C.\nIt can be shown that if \\(F3(A, B; C)\\) is negative, it provides unambiguous proof that population C is admixed between populations A and B, as in the following phylogeny (taken from Figure 1 from (Patterson et al. 2012):\n\nIntuitively, an F3 statistics becomes negative if the allele frequency of the target population C is on average intermediate between the allele frequencies of A and B. Consider as an extreme example a genomic site where \\(a=0\\), \\(b=1\\) and \\(c=0.5\\). Then we have \\((c−a)(c−b)=−0.25\\), which is negative. So if the entire statistics is negative, it suggests that in many positions, the allele frequency c is indeed intermediate, suggesting admixture between the two sources.\nOne way to understand this is by looking what happens to a list of SNPs and allele frequencies for groups A, B and C:\n\n\n\nSNP\nA\nB\nC\n\\((c-a)(c-b)\\)\n\n\n\n\n1\n1\n0\n0.5\n-0.25\n\n\n2\n0.8\n0\n0\n0\n\n\n3\n0\n0.7\n0\n0\n\n\n4\n0.1\n0.5\n0.3\n-0.04\n\n\n5\n0\n0.1\n0.2\n0.02\n\n\n6\n1\n0.2\n0.9\n-0.07\n\n\n\\(F_3(A, B;C)\\)\n\n\n\n-0.057\n\n\n\nEvery SNP where C has an allele frequency intermediate between A and B contributes negatively. Here, the average is also negative, providing evidence for admixture. For statistical certainty, an error bar for this estimate is needed, which is typically computed via Jackknife (see for example the xerxes whitepaper).\n\n\n\n\n\n\nDanger\n\n\n\nIf an F3 statistics is not negative, it does not proof that there is no admixture!\n\n\n\n\nWe will use this statistics to test if Finnish are admixed between East and West, using different Eastern and Western sources. In the West, we use French, Icelandic, Lithuanian and Norwegian as source, and in the East we use Nganasan and one of the ancient individuals analysed in (Lamnidis et al. 2018), from the site of Bolshoy Oleni Ostrov from the Northern Russian Kola-peninsula, and dating to 3500 years before present.\n\n\n\n\n\n\nTip\n\n\n\nIf you happen to have downloaded a copy of the Poseidon Community Archive already, then just use the path to that archive in the following commands. Otherwise you download the entire archive via\n\ntrident fetch -d /somewhere/to/store/the/archive --downloadAll \n\nor just the relevant packages for the examples in this chapter:\n\ntrident fetch -d /somewhere/to/store/the/archive -f \"*2012_PattersonGenetics*,*2014_RaghavanNature*,*2014_LazaridisNature*,*2018_Lamnidis_Fennoscandia*\"\n\n\n\nWe use the software xerxes fstats from the Poseidon Framework. Here is a command line that computes 8 statistics for us:\n\nxerxes fstats -d ~/dev/poseidon-framework/community-archive \\\n    --stat \"F3(Nganasan,French,Finnish)\" \\\n    --stat \"F3(Nganasan, Icelandic, Finnish)\" \\\n    --stat \"F3(Nganasan, Lithuanian, Finnish)\" \\\n    --stat \"F3(Nganasan, Norwegian, Finnish)\" \\\n    --stat \"F3(Russia_Bolshoy, French, Finnish)\" \\\n    --stat \"F3(Russia_Bolshoy, Icelandic, Finnish)\" \\\n    --stat \"F3(Russia_Bolshoy, Lithuanian, Finnish)\" \\\n    --stat \"F3(Russia_Bolshoy, Norwegian, Finnish)\" \\\n\n\n\n\n\n\n\nNote\n\n\n\nNote that xerxes fstats will automatically find the right packages from your local archive that contain these groups. You can see in the output of the program which packages contribute:\n[Info]    5 relevant packages for chosen statistics identified:\n[Info]    *2012_PattersonGenetics-2.1.3*\n[Info]    *2014_LazaridisNature-4.0.2*\n[Info]    *2016_LazaridisNature-2.1.3*\n[Info]    *2018_Lamnidis_Fennoscandia-2.1.0*\n[Info]    *2019_Flegontov_PalaeoEskimo-2.2.1*\nSo these five packages contain the samples requested in these statistics. You can inquire about this also more manually using trident list\n\n\nHere is the result that you should get, nicely layouted in a Text-table:\n.-----------.----------------.------------.---------.---.---------.----------------.--------------------.------------------.---------------------.\n| Statistic |       a        |     b      |    c    | d | NrSites | Estimate_Total | Estimate_Jackknife | StdErr_Jackknife |  Z_score_Jackknife  |\n:===========:================:============:=========:===:=========:================:====================:==================:=====================:\n| F3        | Nganasan       | French     | Finnish |   | 593124  | -1.0450e-3     | -1.0451e-3         | 1.2669e-4        | -8.249133659451905  |\n| F3        | Nganasan       | Icelandic  | Finnish |   | 593124  | -1.1920e-3     | -1.1920e-3         | 1.3381e-4        | -8.908381869946188  |\n| F3        | Nganasan       | Lithuanian | Finnish |   | 593124  | -1.1605e-3     | -1.1605e-3         | 1.5540e-4        | -7.4680182465607245 |\n| F3        | Nganasan       | Norwegian  | Finnish |   | 593124  | -1.0913e-3     | -1.0914e-3         | 1.3921e-4        | -7.83945981272796   |\n| F3        | Russia_Bolshoy | French     | Finnish |   | 542789  | -6.1807e-4     | -6.1809e-4         | 1.0200e-4        | -6.059872900228102  |\n| F3        | Russia_Bolshoy | Icelandic  | Finnish |   | 542789  | -6.2801e-4     | -6.2802e-4         | 1.1792e-4        | -5.325695961373772  |\n| F3        | Russia_Bolshoy | Lithuanian | Finnish |   | 542789  | -3.7310e-4     | -3.7310e-4         | 1.2973e-4        | -2.8760029685791637 |\n| F3        | Russia_Bolshoy | Norwegian  | Finnish |   | 542789  | -3.7646e-4     | -3.7653e-4         | 1.1630e-4        | -3.2375830440434323 |\n'-----------'----------------'------------'---------'---'---------'----------------'--------------------'------------------'---------------------'\n\n\n\n\n\n\nTip\n\n\n\nUse the option -f <FILE> to output the results additionally to a tab-separated file, or --raw if you prefer the standard output to be tab-separated\n\n\nYou can see that in all cases this statistic is negative (Estimate_Total). The next two columns ( Estimate_Jackknife and StdErr_Jackknife) are computed using Jackknifing (see the xerxes whitepaper for details). The last column is the Z score, and it is important here: It gives the deviation of the f3 statistic from zero in units of the standard error. As general rule, a Z score of -3 or more suggests a significant rejection of the Null hypothesis that the statistic is not negative. In this case, all of the statistics are significantly negative (with one borderline exception), proving that Finnish have ancestral admixture of East and West Eurasian ancestry. Here, Eastern ancestry is represented by Nganasan or Russia_Bolshoy, respectively, while Western ancestry by French, Icelandic, Lithuanian and Norwegian, respectively. Note that the statistics does not suggest when this admixture happened!\n\n\n\nAs you will have noticed, the command line above is getting quite long, since a separate --stat option has to be entered for every statistic to be computed. There is a more powerful and elegant interface to xerxes, which uses a configuration file in YAML format. To illustrate it, let us consider the configuration file (which can be found in fstats_working/F3_finnish.config in the git-repository of this book) needed to compute the same statistic as above:\nfstats:\n- type: F3\n  a: [\"Nganasan\", \"Russia_Bolshoy\"]\n  b: [\"French\", \"Icelandic\", \"Lithuanian\", \"Norwegian\"]\n  c: [\"Finnish\"]\nYou can then run xerxes as\nxerxes fstats -d ~/dev/poseidon-framework/community-archive --statConfig fstats_working/F3_finnish.config\nSo xerxes then automatically creates all combinations of populations listed in slots a, b and c.\n\n\n\n\n\n\nNote\n\n\n\nNote that there are actually three types of F3-statistics supported by xerxes:\n\nF3vanilla: The purest form, defined literally as \\(\\langle(c−a)(c−b)\\rangle\\)\nF3: A bias-corrected version, which is only valid for groups in C that have non-zero heterozygosity\nF3star: This one is normalised by the heterozgygosity of the third population, C, as suggested in (Patterson et al. 2012) and implemented in the Admixtools package.\n\nThe white-paper explains this in detail.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe configuration file format has a lot more options. Here is a bit more complex example, but see also the documentation:\n# You can define groups right within the configuration file.\n# here we use negative selection to remove individuals from the\n# newly defined groups\ngroupDefs:\n  CEU2: [\"CEU.SG\", \"-<NA12889.SG>\", \"-<NA12890.SG>\"]\n  FIN2: [\"FIN.SG\", \"-<HG00383.SG>\", \"-<HG00384.SG>\"]\n  GBR2: [\"GBR.SG\", \"-<HG01791.SG>\", \"-<HG02215.SG>\"]\n  IBS2: [\"IBS.SG\", \"-<HG02238.SG>\", \"-<HG02239.SG>\"]\nfstats:\n- type: F2 # this will create 2x2 = 4 F2-Statistics\n  a: [\"French\", \"Spanish\"]\n  b: [\"Han\", \"CEU2\"]\n- type: F3vanilla # This will create 3x2x1 = 6 Statistics\n  a: [\"French\", \"Spanish\", \"Mbuti\"]\n  b: [\"Han\", \"CEU2\"]\n  c: [\"<Chimp.REF>\"]\n- type: F4 # This will create 5x5x4x1 = 100 Statistics\n  a: [\"<I0156.SG>\", \"<I0157.SG>\", \"<I0159.SG>\", \"<I0160.SG>\", \"<I0161.SG>\"]\n  b: [\"<I0156.SG>\", \"<I0157.SG>\", \"<I0159.SG>\", \"<I0160.SG>\", \"<I0161.SG>\"]\n  c: [\"CEU2\", \"FIN2\", \"GBR2\", \"IBS2\"]\n  d: [\"<Chimp.REF>\"]\n# Altogether: 110 statistics of different types\nwhich will not just create multiple statistic using row-combinations, as described, but also uses newly defined groups and combines multiple statistic types (F2, F3 and F4) in one run."
  },
  {
    "objectID": "fstats.html#f4-statistics",
    "href": "fstats.html#f4-statistics",
    "title": "3  Introduction to F3- and F4-Statistics",
    "section": "3.2 F4 Statistics",
    "text": "3.2 F4 Statistics\nA different way to test for admixture is by “F4 statistics” (or “D statistics” which is very similar), also introduced in (Patterson et al. 2012).\nF4 statistics are also defined in terms of correlations of allele frequency differences, similarly to F3 statistics, but involving four different populations, not just three. Specifically we define\n\\[F4(A,B;C,D)=\\langle(a−b)(c−d)\\rangle.\\]\n\n3.2.1 Shaping intuition - the ABBA- and BABA-sites\nTo understand the statistics, consider the following tree:\n\nIn this tree, without any additional admixture, the allele frequency difference between A and B should be completely independent from the allele frequency difference between C and D. In that case, F4(A, B; C, D) should be zero, or at least not statistically different from zero. However, if there was gene flow from C or D into A or B, the statistic should be different from zero. Specifically, if the statistic is significantly negative, it implies gene flow between either C and B, or D and A. If it is significantly positive, it implies gene flow between A and C, or B and D.\nIt is helpful to again consider an example using a SNP list, this time assuming that every population is just a single (haploid) individual, so each allele frequency can just be 0 or 1. For example:\n\n\n\nSNP\nA\nB\nC\nD\n\\((a-b)(c-d)\\)\n\n\n\n\n1\n1\n0\n0\n0\n0\n\n\n2\n1\n0\n1\n1\n0\n\n\n3\n0\n1\n1\n0\n-1\n\n\n4\n0\n1\n0\n1\n1\n\n\n5\n1\n0\n0\n1\n-1\n\n\n6\n1\n0\n0\n0\n0\n\n\n\\(F_4(A, B;C, D)\\)\n\n\n\n\n-0.0167\n\n\n\nYou can see that the only SNPs that contribute positively to this statistics are SNPs where the alleles are distributed as 1010 and 0101, and the only SNPs that contribute negatively are 1001 and 0110. In the literature, the two patterns have been dubbed “ABBA” and “BABA”, which is why the statistical test behind this statistic (see below) was sometimes called the ABBA-BABA test (see for example (Martin, Davey, and Jiggins 2015)).\nThe intuition here is straight-forward: In positions that are polymorphic in both \\((A,B)\\) and \\((C,D)\\), this statistic asks whether B is genetically more similar to C than it is to D. This is most useful as a test for “treeness”: If A, B, C, D are related to each other as indicated in the above tree, then C should be equally closely related to C as to D. But if we actually find evidence that B is closer to C than to D, or vice versa, then this means that the tree above cannot be correct, but that there must be a closer connection between B and C or B and D, depending on the sign of the statistic.\n\n\n3.2.2 From single samples to allele frequencies\nSo the ABBA- and BABA-categories of SNPs help shape intuition for how this statistic behaves for single haploid genomes. But what about population allele frequencies? Looking back at the formula \\(\\langle(a−b)(c−d)\\rangle\\) this doesn’t help very much with intuition how this behaves with frequencies. Well, a nice feature of F4-Statistics is that averages factor out. This means, that if you have multiple samples in one or multiple slots A, B, C or D, the total F4-statistic of the groups is exactly equal to the average of F4-Statistics of the individuals. Here is a more mathematical definition.\nLet’s say we have 2 individuals in each of A and B, so we may perhaps write \\(A=\\{A_1,A_2\\}\\) and \\(B=\\{B_1,B_2\\}\\). Then one can show to have\n\\[F4(A, B; C, D) = \\text{Average of}[F4(A_1, B_1; C, D), F4(A_1, B_2; C, D), F4(A_2, B_1; C, D), F4(A_2, B_2; C, D)]\\]\nso just thte average over all individual-based F4-statistics. And this can be shown to be true for arbitrary numbers of samples. So in other words: An F4-Statistic always measures the average excess of pairwise BABA SNPs over ABBA SNPs. To me, this is a useful insight, as I find thinking in terms of ABBA-BABA somehow more helpful than thinking in terms of correlations of allele-frequency differences (which is really what the original formula is).\n\n\n\n\n\n\nNote\n\n\n\nF4-statistics have been famously used to show that Neanderthals are more closely related to Non-African populations than to Africans, suggesting gene-flow between Neanderthals and Non-Africans (shown in (Green et al. 2010)). You can reproduce this famous result with\n\nxerxes fstats -d ~/poseidon_repo --stat 'F4(<Chimp.REF>,<Altai_published.DG>,Yoruba,French)' \\\n  --stat 'F4(<Chimp.REF>,<Altai_published.DG>,Sardinian,French)'\n\nwhich shows that the first statistic is significantly positive with a Z-score of 7.99, while the second one is insignificantly different from zero (Z=1.01)\n\n\nThe way this statistic is often used, is to put a divergent outgroup as population A, for which we know for sure that there was no admixture into either C or D. With this setup, we can then test for gene flow between B and D (if the statistic is positive), or B and C (if it is negative).\n\n\n3.2.3 Running F4-Statistics with xerxes\nHere, we can use this statistic to test for East Asian admixture in Finns, similarly to the test using Admixture F3 statistics above. We will again use xerxes fstats. We again prepare a configuration file (in fstats_working/F4_finish.config in the git-repository of this book), this time with four populations (A, B, C, D):\nfstats:\n- type: F4\n  a: [\"Mbuti\"]\n  b: [\"Nganasan\", \"Russia_Bolshoy\"]\n  c: [\"French\", \"Icelandic\", \"Lithuanian\", \"Norwegian\"]\n  d: [\"Finnish\"]\nYou can again run via\n\nxerxes fstats -d ~/dev/poseidon-framework/community-archive --statConfig fstats_working/F4_finnish.config\n\nThe result is:\n.-----------.-------.----------------.------------.---------.---------.----------------.--------------------.------------------.--------------------.\n| Statistic |   a   |       b        |     c      |    d    | NrSites | Estimate_Total | Estimate_Jackknife | StdErr_Jackknife | Z_score_Jackknife  |\n:===========:=======:================:============:=========:=========:================:====================:==================:====================:\n| F4        | Mbuti | Nganasan       | French     | Finnish | 593124  | 2.3114e-3      | 2.3115e-3          | 1.2676e-4        | 18.235604067907143 |\n| F4        | Mbuti | Nganasan       | Icelandic  | Finnish | 593124  | 1.6590e-3      | 1.6590e-3          | 1.4861e-4        | 11.163339072181776 |\n| F4        | Mbuti | Nganasan       | Lithuanian | Finnish | 593124  | 1.3290e-3      | 1.3290e-3          | 1.4681e-4        | 9.052979707622278  |\n| F4        | Mbuti | Nganasan       | Norwegian  | Finnish | 593124  | 1.6503e-3      | 1.6503e-3          | 1.5358e-4        | 10.745850997260929 |\n| F4        | Mbuti | Russia_Bolshoy | French     | Finnish | 542789  | 1.8785e-3      | 1.8785e-3          | 1.2646e-4        | 14.854487416366263 |\n| F4        | Mbuti | Russia_Bolshoy | Icelandic  | Finnish | 542789  | 1.0829e-3      | 1.0828e-3          | 1.4963e-4        | 7.236818881873822  |\n| F4        | Mbuti | Russia_Bolshoy | Lithuanian | Finnish | 542789  | 5.4902e-4      | 5.4907e-4          | 1.4601e-4        | 3.7605973064589096 |\n| F4        | Mbuti | Russia_Bolshoy | Norwegian  | Finnish | 542789  | 9.3473e-4      | 9.3475e-4          | 1.5302e-4        | 6.108881868125652  |\n'-----------'-------'----------------'------------'---------'---------'----------------'--------------------'------------------'--------------------'\nAs you can see, in all cases, the Z score is positive and larger than 3, indicating a significant deviation from zero, and implying gene flow between Nganasan and Finnish, and BolshoyOleniOstrov and Finnish, when compared to French, Icelandic, Lithuanian or Norwegian."
  },
  {
    "objectID": "fstats.html#outgroup-f3-statistics",
    "href": "fstats.html#outgroup-f3-statistics",
    "title": "3  Introduction to F3- and F4-Statistics",
    "section": "3.3 Outgroup-F3-Statistics",
    "text": "3.3 Outgroup-F3-Statistics\nOutgroup F3 statistics are a special case how to use F3 statistics. The definition is the same as for Admixture F3 statistics, but instead of a target C and two source populations A and B, one now gives an outgroup C and two test populations A and B.\nTo get an intuition for this statistics, consider the following tree:\n\nIn this scenario, the statistic F3(A, B; C) measures the branch length from C to the common ancestor of A and B, coloured red. So this statistic is simply a measure of how closely two population A and B are related with each other, as measured from a distant outgroup. It is thus a similarity measure: The higher the statistic, the more genetically similar A and B are to one another.\nHere is again a SNP table to illustrate, using haploid individuals:\n\n\n\nSNP\nA\nB\nC\n\\((c-a)(c-b)\\)\n\n\n\n\n1\n1\n0\n0\n0\n\n\n2\n1\n0\n0\n0\n\n\n3\n0\n0\n1\n1\n\n\n4\n1\n0\n1\n0\n\n\n5\n1\n1\n0\n1\n\n\n6\n0\n0\n1\n1\n\n\n\\(F_3(A, B;C)\\)\n\n\n\n0.5\n\n\n\nYou can see that each position which is similar between A and B, but different to C contributes 1, all other SNPs 0. So it directly measures similarity between A and B on alleles that differ from the outgroup C.\n\n\n\n\n\n\nNote\n\n\n\nNote that the averaging-relation shown for F4 statistics above is also true for Outgroup-F3 statistics, but only for populations A and B, not for C. So if you have multiple samples in A and B, you may think of this statistic being the average over all pairwise nucleotide similarities between individuals in A and B with respect to the same outgroup C.\n\n\nWe can use this statistic to measure for example the genetic affinity to East Asia, by performing the statistic F3(Han, X; Mbuti), where Mbuti is a distant African population and acts as outgroup here, Han denote Han Chinese, and X denotes various European populations that we want to test.\nYou can again define a configuration file that performs looping over various populations X for you:\nfstats:\n- type: F3\n  a: [\"Han\"]\n  b: [\"Chuvash\", \"Albanian\", \"Armenian\", \"Bulgarian\", \"Czech\", \"Druze\", \"English\",\n      \"Estonian\", \"Finnish\", \"French\", \"Georgian\", \"Greek\", \"Hungarian\", \"Icelandic\",\n      \"Italian_North\", \"Italian_South\", \"Lithuanian\", \"Maltese\", \"Mordovian\", \"Norwegian\",\n      \"Orcadian\", \"Russian\", \"Sardinian\", \"Scottish\", \"Sicilian\", \"Spanish_North\",\n      \"Spanish\", \"Ukrainian\", \"Finland_Levanluhta\", \"Russia_Bolshoy\", \"Russia_Chalmny_Varre\", \"Saami.DG\"]\n  c: [\"Mbuti\"]\nwhich cycles through many populations from Europe, including the ancient individuals from Chalmny Varre, Bolshoy Oleni Ostrov and Levänluhta (described in (Lamnidis et al. 2018)). We store this file in a file called fstats_working/OutgroupF3_europe.config and run via:\n\nxerxes fstats --statConfig fstats_working/OutgroupF3_europe.config -d ~/dev/poseidon-framework/community-archive -f fstats_working/outgroupf3_europe.tsv\n\n\n\n\n\n\n\nWarning\n\n\n\nOften in Outgroup-F3-statistics you use single genomes for population C, sometimes even single haploid genomes. In this case, F3 and F3star will get undefined results, because ordinary F3 and F3star statistics require population C to have non-zero average heterozygosity, so you will need at least one diploid sample, or multiple haploid or diploid samples.\nUse F3vanilla if your third population C is a single pseudo-haploid sample.\n\n\nHere is the output of this run (but note that a tab-separated version was also stored in fstats_working/outgroupf3_europe.tsv using the option -f):\n.-----------.-----.----------------------.-------.---.---------.----------------.--------------------.------------------.--------------------.\n| Statistic |  a  |          b           |   c   | d | NrSites | Estimate_Total | Estimate_Jackknife | StdErr_Jackknife | Z_score_Jackknife  |\n:===========:=====:======================:=======:===:=========:================:====================:==================:====================:\n| F3        | Han | Chuvash              | Mbuti |   | 593124  | 5.3967e-2      | 5.3967e-2          | 5.0668e-4        | 106.51180329550319 |\n| F3        | Han | Albanian             | Mbuti |   | 593124  | 4.9972e-2      | 4.9973e-2          | 4.9520e-4        | 100.91326321202445 |\n| F3        | Han | Armenian             | Mbuti |   | 593124  | 4.9531e-2      | 4.9531e-2          | 4.7771e-4        | 103.68366652942314 |\n| F3        | Han | Bulgarian            | Mbuti |   | 593124  | 5.0103e-2      | 5.0103e-2          | 4.8624e-4        | 103.04188532686614 |\n| F3        | Han | Czech                | Mbuti |   | 593124  | 5.0536e-2      | 5.0536e-2          | 4.9261e-4        | 102.58792370749681 |\n| F3        | Han | Druze                | Mbuti |   | 593124  | 4.8564e-2      | 4.8564e-2          | 4.6788e-4        | 103.79674299622445 |\n| F3        | Han | English              | Mbuti |   | 593124  | 5.0280e-2      | 5.0281e-2          | 4.9183e-4        | 102.23198323949656 |\n| F3        | Han | Estonian             | Mbuti |   | 593124  | 5.1154e-2      | 5.1155e-2          | 5.0350e-4        | 101.59882496016485 |\n| F3        | Han | Finnish              | Mbuti |   | 593124  | 5.1784e-2      | 5.1784e-2          | 5.0603e-4        | 102.33488758899031 |\n| F3        | Han | French               | Mbuti |   | 593124  | 5.0207e-2      | 5.0208e-2          | 4.8552e-4        | 103.40976592749682 |\n| F3        | Han | Georgian             | Mbuti |   | 593124  | 4.9711e-2      | 4.9711e-2          | 4.8100e-4        | 103.34881140790415 |\n| F3        | Han | Greek                | Mbuti |   | 593124  | 4.9874e-2      | 4.9874e-2          | 4.8994e-4        | 101.79554640756365 |\n| F3        | Han | Hungarian            | Mbuti |   | 593124  | 5.0497e-2      | 5.0498e-2          | 4.9878e-4        | 101.24215699276706 |\n| F3        | Han | Icelandic            | Mbuti |   | 593124  | 5.0680e-2      | 5.0680e-2          | 4.9729e-4        | 101.91303336514295 |\n| F3        | Han | Italian_North        | Mbuti |   | 593124  | 4.9903e-2      | 4.9904e-2          | 4.8436e-4        | 103.03094306099203 |\n| F3        | Han | Italian_South        | Mbuti |   | 592980  | 4.9201e-2      | 4.9201e-2          | 5.1170e-4        | 96.15239597674244  |\n| F3        | Han | Lithuanian           | Mbuti |   | 593124  | 5.0896e-2      | 5.0896e-2          | 5.0638e-4        | 100.50984037418753 |\n| F3        | Han | Maltese              | Mbuti |   | 593124  | 4.8751e-2      | 4.8751e-2          | 4.7500e-4        | 102.63442479673623 |\n| F3        | Han | Mordovian            | Mbuti |   | 593124  | 5.1820e-2      | 5.1820e-2          | 4.8853e-4        | 106.07409963190884 |\n| F3        | Han | Norwegian            | Mbuti |   | 593124  | 5.0724e-2      | 5.0724e-2          | 4.9514e-4        | 102.4454387098217  |\n| F3        | Han | Orcadian             | Mbuti |   | 593124  | 5.0469e-2      | 5.0469e-2          | 4.9485e-4        | 101.98814656611475 |\n| F3        | Han | Russian              | Mbuti |   | 593124  | 5.1277e-2      | 5.1277e-2          | 4.8613e-4        | 105.48070801791317 |\n| F3        | Han | Sardinian            | Mbuti |   | 593124  | 4.9416e-2      | 4.9417e-2          | 4.8908e-4        | 101.04049389691913 |\n| F3        | Han | Scottish             | Mbuti |   | 593124  | 5.0635e-2      | 5.0635e-2          | 5.0565e-4        | 100.13962104744425 |\n| F3        | Han | Sicilian             | Mbuti |   | 593124  | 4.9194e-2      | 4.9194e-2          | 4.8157e-4        | 102.15353663091187 |\n| F3        | Han | Spanish_North        | Mbuti |   | 593124  | 5.0032e-2      | 5.0032e-2          | 4.9377e-4        | 101.32594226555439 |\n| F3        | Han | Spanish              | Mbuti |   | 593124  | 4.9693e-2      | 4.9693e-2          | 4.8551e-4        | 102.35200847948641 |\n| F3        | Han | Ukrainian            | Mbuti |   | 593124  | 5.0731e-2      | 5.0731e-2          | 4.9506e-4        | 102.47529111692852 |\n| F3        | Han | Finland_Levanluhta   | Mbuti |   | 303033  | 5.4488e-2      | 5.4488e-2          | 5.7681e-4        | 94.46487653920919  |\n| F3        | Han | Russia_Bolshoy       | Mbuti |   | 542789  | 5.7273e-2      | 5.7273e-2          | 5.2875e-4        | 108.31739594898687 |\n| F3        | Han | Russia_Chalmny_Varre | Mbuti |   | 428215  | 5.4000e-2      | 5.4000e-2          | 5.6936e-4        | 94.84371082564112  |\n| F3        | Han | Saami.DG             | Mbuti |   | 585193  | 5.4727e-2      | 5.4728e-2          | 5.5546e-4        | 98.5265149143263   |\n'-----------'-----'----------------------'-------'---'---------'----------------'--------------------'------------------'--------------------'\nNow it’s time to plot these results using R. Let’s first read in the table:\n\nd <- read.csv(\"fstats_working/outgroupf3_europe.tsv\", sep = \"\\t\")\n\nWe can check that it worked:\n\nhead(d)\n\n  Statistic   a         b     c  d NrSites Estimate_Total Estimate_Jackknife\n1        F3 Han   Chuvash Mbuti NA  593124       0.053967           0.053967\n2        F3 Han  Albanian Mbuti NA  593124       0.049972           0.049973\n3        F3 Han  Armenian Mbuti NA  593124       0.049531           0.049531\n4        F3 Han Bulgarian Mbuti NA  593124       0.050103           0.050103\n5        F3 Han     Czech Mbuti NA  593124       0.050536           0.050536\n6        F3 Han     Druze Mbuti NA  593124       0.048564           0.048564\n  StdErr_Jackknife Z_score_Jackknife\n1       0.00050668          106.5118\n2       0.00049520          100.9133\n3       0.00047771          103.6837\n4       0.00048624          103.0419\n5       0.00049261          102.5879\n6       0.00046788          103.7967\n\n\nNice, now on to plotting (here I’m using Base R for zero-dependency pain, you’re welcome!):\n\norder <- order(d$Estimate_Total) # order the estimates for visual effect\nx <- d$Estimate_Jackknife[order]\nxErr <- d$StdErr_Jackknife[order]\ny <- seq_along(d$b)\nplot(x, y, xlab = \"Z Score\", ylab = NA, yaxt = \"n\", # plot no y-axis ticks\n     xlim = c(0.048,0.06),\n     main = \"F3(Han, X; Mbuti)\")\n# plot the labels\ntext(x + 0.001, y, labels = d$b, adj=0)\n# plot the error bars\narrows(x - xErr, y, x + xErr, y, length=0.05, angle=90, code=3)\n\n\n\n\n\n\n\n\nAs expected, the ancient samples and modern Saami are the ones with the highest allele sharing with present-day East Asians (as represented by Han) compared to many other Europeans.\n\n\n\n\nGreen, Richard E, Johannes Krause, Adrian W Briggs, Tomislav Maricic, Udo Stenzel, Martin Kircher, Nick Patterson, et al. 2010. “A Draft Sequence of the Neandertal Genome.” Science 328 (5979): 710–22. http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=20448178&retmode=ref&cmd=prlinks.\n\n\nLamnidis, Thiseas C, Kerttu Majander, Choongwon Jeong, Elina Salmela, Anna Wessman, Vyacheslav Moiseyev, Valery Khartanovich, et al. 2018. “Ancient Fennoscandian Genomes Reveal Origin and Spread of Siberian Ancestry in Europe.” Nature Communications 9 (1): 5018. https://doi.org/10.1038/s41467-018-07483-5.\n\n\nMartin, Simon H, John W Davey, and Chris D Jiggins. 2015. “Evaluating the Use of ABBA-BABA Statistics to Locate Introgressed Loci.” Molecular Biology and Evolution 32 (1): 244–57. https://doi.org/10.1093/molbev/msu269.\n\n\nPatterson, Nick, Priya Moorjani, Yontao Luo, Swapan Mallick, Nadin Rohland, Yiping Zhan, Teri Genschoreck, Teresa Webster, and David Reich. 2012. “Ancient Admixture in Human History.” Genetics 192 (3): 1065–93. https://doi.org/10.1534/genetics.112.145037.\n\n\nPeter, Benjamin M. 2016. “Admixture, Population Structure, and F-Statistics.” Genetics 202 (4): 1485–1501. https://doi.org/10.1534/genetics.115.183913."
  },
  {
    "objectID": "eager.html#why-do-we-need-nf-coreeager",
    "href": "eager.html#why-do-we-need-nf-coreeager",
    "title": "4  Introduction to nf-core/eager",
    "section": "4.1 Why do we need nf-core/eager?",
    "text": "4.1 Why do we need nf-core/eager?\n\nCompared to other Next-Generation Sequencing data, the chemical structure and increased risk of present-day contamination require methods specialized for ancient DNA in both the wet and the dry lab.\nEnsuring the authenticity of ancient genomic data is one of the main focuses of bioinformatic tools developed for the study of ancient DNA and underlines the necessity of reproducibility of results.\nWith an increasing number of laboratories contributing to the field, the available computational resources and previous bioinformatic experience varies greatly. To increase accessibility, newly developed tools should be adaptable to different environments, efficient, consistently maintained and well-documented."
  },
  {
    "objectID": "eager.html#what-can-nf-coreeager-do",
    "href": "eager.html#what-can-nf-coreeager-do",
    "title": "4  Introduction to nf-core/eager",
    "section": "4.2 What can nf-core/eager do?",
    "text": "4.2 What can nf-core/eager do?\nnf-core/eager streamlines the initial steps of ancient DNA analysis from FASTQ files after sequencing to variant calling (Fellows Yates et al. 2021).\n\nPreprocessing:\n\nFastQC (sequencing quality control)\nAdapterRemoval2/fastp (sequencing artifact clean-up)\n\nMapping:\n\nBWA aln/BWA mem/CircularMapper/Bowtie2 (alignment)\nSAMtools (mapping quality filtering)\nPicard MarkDuplicates/DeDup (PCR duplicate removal)\nSAMtools/PreSeq/Qualimap2/BEDtools/Sex.DetERRmine/EndorSpy/MtNucRatio (mapping statistics)\n\naDNA evaluation:\n\nDamageProfiler/mapDamage2 (damage assessment)\nPMDtools (aDNA read selection)\nmapDamage2/Bamutils (damage removal)\nANGSD (human contamination estimation)\nBBduk/HOPS/Kraken & Kraken Parse/MALT & MaltExtract (metagenomic screening)\n\nVariant calling: GATK UnifiedGenotyper & HaplotypeCaller/sequenceTools pileupCaller/VCF2Genome/MultiVCFAnalyzer/freebayes/ANGSD\nReport generation: MultiQC (summarize all generated statistics)"
  },
  {
    "objectID": "eager.html#how-do-i-use-nf-coreeager",
    "href": "eager.html#how-do-i-use-nf-coreeager",
    "title": "4  Introduction to nf-core/eager",
    "section": "4.3 How do I use nf-core/eager?",
    "text": "4.3 How do I use nf-core/eager?\n\n4.3.1 Installation\nYou need:\n\na Unix machine (HPC-cluster or a computer running Linux or MacOS)\nan installation of docker or apptainer (formerly known as singularity) or conda, java and nextflow (e.g. via conda)\ninternet connection\n\nDownload the latest version of nf-core/eager\nnextflow pull nf-core/eager \n# for a specific version\nnextflow pull nf-core/eager -r 2.5.0\nRun a test specifying your choice of conda, docker or singularity\nnextflow run nf-core/eager -r 2.5.0 -profile test_tsv,docker\nTo optimize the use of available clusters, queues and resources, check if a Nextflow pipeline configuration is already available for your institution or computing environment. If not, prepare a custom profile tailored to your computational resources and setup. These are then added as a profile.\nnextflow run nf-core/eager -r 2.5.0 -profile test_tsv,eva #for MPI-EVA\n\n\n4.3.2 Input preparation\nYou can run nf-core/eager by providing either a path to fastq or bam files or a path to a tab-separated table of input data to --input. For a large number of samples and convenience, a tsv is usually the preferred option. Using a tsv input also allows for merging of different files (e.g. different libraries, different UDG treatments, etc.) at different stages of the pipeline.\n\n\n\nPipeline stages and merging steps performed for a single sample with different libraries and different UDG treatments.\n\n\nA tsv input file contains the following columns, detailing the name of the sample, library, sequencing lane, colour chemistry depending on the sequencer used, target organism, library strandedness, UDG treatment, path to fastq with forward reads (SE and PE), path to reverse reads (only PE), path to bam (optional). nf-core/eager will treat the data according to the provided information, e.g. only trim UDG half data and genotype single-stranded libraries using single-stranded mode.\nSample_Name Library_ID Lane Colour_Chemistry SeqType Organism Strandedness UDG_Treatment R1                                                                                                                                  R2                                                                                                                                  BAM\nJK2782      JK2782     1    4                PE      Mammoth  single       half          https://github.com/nf-core/test-datasets/raw/eager/testdata/Mammoth/fastq/JK2782_TGGCCGATCAACGA_L008_R1_001.fastq.gz.tengrand.fq.gz https://github.com/nf-core/test-datasets/raw/eager/testdata/Mammoth/fastq/JK2782_TGGCCGATCAACGA_L008_R2_001.fastq.gz.tengrand.fq.gz NA\nJK2802      JK2802     2    2                SE      Mammoth  double       full          NA                                                                                                                                  NA                                                                                                                                  https://github.com/nf-core/test-datasets/raw/eager/testdata/Mammoth/fastq/JK2802_AGAATAACCTACCA_L008_R1_001.fastq.gz.tengrand.bam\nCollecting and double-checking this information is time consuming, but crucial!\nIf you realize you have different libraries from same individual, you should enter the same Sample_Name for all respective libraries. nf-core/eager will then produce all steps for the independent libraries (e.g. endogenous DNA, sequencing quality control, contamination estimation, etc.), but merge the deduplicated bam files before genotyping, genetic sex estimation and coverage calculation. To avoid re-mapping the whole dataset and conserve computing resources, also consider providing the mapped bam files to nf-core/eager directly.\n\n\n\n\n\n\nTip\n\n\n\nAt DAG, we can take advantage of all the information entered in Pandora to produce a eager-ready tsv with pandora2eager.\n\n\n\n\n4.3.3 Parameter customization\nBy default nf-core/eager runs the following, when you only provide input data and a reference genome:\nnextflow run nf-core/eager --input <INPUT>.tsv --fasta '<REFERENCE>.fasta' -profile eva\n\nPreprocessing:\n\nFastQC (sequencing quality control)\nAdapterRemoval2 (sequencing artifact clean-up)\n\nMapping:\n\nBWA aln (alignment)\nPicard MarkDuplicates (PCR duplicate removal)\nSAMtools/PreSeq/Qualimap2/EndorSpy (mapping statistics)\n\naDNA evaluation: DamageProfiler (damage assessment)\nReport generation: MultiQC (summarize all generated statistics)\n\nThe most direct way to add analysis steps (e.g. turn on genotyping) or change settings (e.g. shorter read length cut-off) is to add more parameters to the command line, in this case --run_genotyping --genotyping_tool pileupcaller and --clip_readlength 25, respectively. However, this gets cumbersome for the rather extensive workflows we usually employ for human aDNA analysis, including read trimming based on UDG treatment, genetic sex estimation, human nuclear contamination estimation, mitochondrial to nuclear ratio estimation and genotyping.\nBut the power of nf-core/eager lies in its adaptability to your specific analysis needs and the possibility to ‘remember’ your favorite settings with a personal configuration file. This separate file can contain all parameters for your required tools, as well as custom computational resource requests. For 1240K capture data, a profile mapping to the hs37d5 reference genome with genotyping could look like this:\nprofiles{\n  TF_hs37 { #name of the profile\n    params {\n        config_profile_description = \"human 1240K data hs37d5 + genotyping\"\n        config_profile_contact = \"Selina Carlhoff (@scarlhoff)\"\n        email = \"selina_carlhoff@eva.mpg.de\"\n        snpcapture_bed = \"/PATH/1240K.pos.list_hs37d5.0based.bed\"\n        fasta = \"/PATH/hs37d5/hs37d5.fa\"\n        fasta_index = \"/PATH/hs37d5/hs37d5.fa.fai\"\n        bwa_index = \"/PATH/hs37d5/\"\n        skip_preseq = true\n        clip_readlength = 30\n        preserve5p = true\n        bwaalnn = 0.01\n        bwaalnl = 16500\n        run_bam_filtering = true\n        bam_mapping_quality_threshold = 30\n        bam_filter_minreadlength = 30\n        bam_unmapped_type = \"discard\"\n        run_trim_bam = true\n        bamutils_clip_double_stranded_half_udg_left = 2\n        bamutils_clip_double_stranded_half_udg_right = 2\n        bamutils_clip_single_stranded_none_udg_left = 0\n        bamutils_clip_single_stranded_none_udg_right = 0\n        run_genotyping = true\n        genotyping_tool = \"pileupcaller\"\n        genotyping_source = \"trimmed\"\n        pileupcaller_bedfile = \"/PATH/1240K.pos.list_hs37d5.0based.bed\"\n        pileupcaller_snpfile = \"/PATH/1240K.snp\"\n        run_mtnucratio = true\n        mtnucratio_header = \"MT\"\n        run_sexdeterrmine = true\n        sexdeterrmine_bedfile = \"/PATH/1240K.pos.list_hs37d5.0based.bed\"\n        run_nuclear_contamination = true\n        contamination_chrom_name = \"X\"\n    }\n    process {\n    maxRetries = 2\n        withName:bwa {\n        time = { task.attempt == 3 ? 1440.h : task.attempt == 2 ? 72.h : 48.h }\n        }\n        withName:markduplicates {\n        memory = { task.attempt == 3 ? 16.GB : task.attempt == 2 ? 8.GB : 4.GB }\n        }\n        withName: mtnucratio {\n            memory = '10.G'\n            time = '24.h'\n        }\n    }\n  }\n}\nThe configuration file is then provided to nf-core/eager via the -profile and -c flag.\nnextflow run nf-core/eager -–input <INPUT>.tsv -profile TF_hs37,eva,archgen -c /<PATH>/eager2.config\nFull documentation of all parameters is available on the nf-core/eager website.\n\n\n\n\n\n\nTip\n\n\n\nThe standardised parameters for the DAG automated pipeline can be found at /mnt/archgen/Autorun_eager/conf/Autorun.config.\n\n\n\n\n4.3.4 Run submission\nOnce all input files and parameters are prepared, you are ready for submission. To make sure that the workflow continues running when you disconnect from the cluster or shut down your computer, nf-core/eager should be run in a screen session.\n# create a screen session\nscreen -R eager\n# submit nf-core/eager run\nnextflow run nf-core/eager –input <INPUT>.tsv -profile <YOUR_PROFILE> -c /<PATH>/<YOUR_CONFIG>.config\n# disconnect from screen session by pressing Ctrl+A+D\n# reconnect to screen session\nscreen -r eager\n# end screen session after successful pipeline execution\nexit\nAfter submitting a command specifying all the parameters you would like to use, Nextflow generates the corresponding shell scripts and submits each job to your scheduler according to your requested computational resources. You can track the execution status live in the terminal or on Nextflow Tower. For use with tower, you should assign the run an identifiable name with -name and activate tracking using -with-tower.\n\n\n4.3.5 Output\nDuring the progression of the run, the results of each pipeline steps are collected in separate output directories. These contain the raw outputs of each tool, including any generated files (e.g. deduplicated bam files or genotypes).\n<RUNNAME>/\n- results/\n  - adapterremoval/\n  - damageprofiler/\n  - deduplication/\n  - documentation/\n  - endorspy/\n  - fastqc/\n  - genotyping/\n  - lanemerging/\n  - mapping/\n  - merged_bams/\n  - multiqc/\n  - nuclear_contamination/\n  - pipeline_info/\n  - qualimap/\n  - reference_genome/\n  - samtools/\n  - sex_determination/\n  - trimmed_bam/\n- work/\nBut as a first overview, we want to look at the summary of all statistics aggregated in multiqc/multiqc_report.html.\n\n\n\nScreenshot of the top section of a MultiQC report\n\n\nThis table collects the output from all tools, so you can get an overview of sequenced reads per sequencing run, endogenous DNA per library, covered SNPs per sample and much more. You can also inspect and export crucial plots, such as read length distribution and damage profile. The end of the report also contains a list of all software versions and an overview of which profiles were used.\n\n\n\nAncient DNA damage plot as generated by MultiQC\n\n\n\n\n4.3.6 Trouble shooting\nA common issue with nf-core/eager, especially when used in combination with the SGE scheduler, are memory issues with java-driven tools, e.g. MarkDuplicates. Sometimes the pipeline does not catch cases properly, where the allocated memory is exceeded, and the job keeps running instead of being re-submitted with larger memory allocation. Therefore, if you notice jobs running much longer than expected, it is worth checking the work/ directory, where all information about each submitted job is recorded. Each job is assigned a randomly generated name using numbers and letter which you can identify from the log printed in to your screen, the <RUNNAME>/.nextflow.log or Nextflow tower. Each work directory contains files tracing the execution of the job.\n<RUNNAME>/\n- work/\n  - <WORKDIRECTORY>/\n    - .command.sh # exact command run for this tool\n    - .command.run # exact command submitted to the scheduler\n    - .command.log # any messages during the execution\n    - .command.err # any error messages\n    - .command.out # any output messages\n    - .command.trace # assigned computational resources\nIf you spot java.lang.OutOfMemoryError: unable to create new native thread in .command.log or command.err, you can delete the individual job from the scheduling queue. It will be re-submitted automatically with larger memory allocation.\nIf you’ve had an issue with a run or want to restart the pipeline, you can do so using -resume. Nextflow will used cached results from any pipeline steps where the inputs are the same, continuing from where it got to previously. You can also supply a run name to resume a specific run: -resume [run-name]. Use the nextflow log command to show previous run names."
  },
  {
    "objectID": "eager.html#how-do-i-report-the-usage-of-nf-coreeager",
    "href": "eager.html#how-do-i-report-the-usage-of-nf-coreeager",
    "title": "4  Introduction to nf-core/eager",
    "section": "4.4 How do I report the usage of nf-core/eager?",
    "text": "4.4 How do I report the usage of nf-core/eager?\nIf you use nf-core/eager for your analysis, please cite Fellows Yates et al. (2021) and the release of nf-core/eager on zenodo, as well as the nf-core publication (Ewels et al. 2020). As nf-core/eager is only the pipeline connecting multiple tools, please also cite the version of each used tool, the respective individual publications and add the full command for easy reproducibility.\n\nFellows Yates, James A., Thiseas C. Lamnidis, Maxime Borry, Aida Andrades Valtueña, Zandra Fagernäs, Stephen Clayton, Maxime U. Garcia, Judith Neukamm, and Alexander Peltzer. 2021. “Reproducible, Portable, and Efficient Ancient Genome Reconstruction with Nf-Core/Eager.” PeerJ 9 (March): e10947. https://doi.org/10.7717/peerj.10947.\n\nEwels, Philip A., Alexander Peltzer, Sven Fillinger, Harshil Patel, Johannes Alneberg, Andreas Wilm, Maxime Ulysse Garcia, Paolo Di Tommaso, and Sven Nahnsen. 2020. “The Nf-Core Framework for Community-Curated Bioinformatics Pipelines.” Nature Biotechnology 38 (3): 276–78. https://doi.org/10.1038/s41587-020-0439-x.\nnextflow run nf-core/eager\n        -profile eva,archgen\n        -r 2.4.0\n        --input <INPUT>.tsv\n        --min_adap_overlap 1\n        --clip_readlength 30\n        --clip_min_read_quality 20\n        --preserve5p\n        --mapper bwaaln\n        --bwaalnnn 0.01\n        --bwaalno 2\n        --run_bam_filtering true\n        --bam_mapping_quality_threshold 30\n        --bam_filter_minreadlength 30\n        --bam_unmapped_type discard\n        --dedupper markduplicates\n        --damageprofiler_length 100\n        --damageprofiler_threshold 15\n        --damageprofiler_yaxis 0.3"
  },
  {
    "objectID": "eager.html#how-do-i-update-nf-coreeager",
    "href": "eager.html#how-do-i-update-nf-coreeager",
    "title": "4  Introduction to nf-core/eager",
    "section": "4.5 How do I update nf-core/eager?",
    "text": "4.5 How do I update nf-core/eager?\nnextflow pull nf-core/eager\n#or for a specific version\nnextflow pull nf-core/eager -r 2.5.0"
  },
  {
    "objectID": "eager.html#whats-next-for-nf-coreeager",
    "href": "eager.html#whats-next-for-nf-coreeager",
    "title": "4  Introduction to nf-core/eager",
    "section": "4.6 What’s next for nf-core/eager?",
    "text": "4.6 What’s next for nf-core/eager?\nWhile nf-core/eager 2.5.0 has only been released recently, behind the scenes the development team has been very busy re-writing nf-core/eager to be more efficient and include even more functionality. So look out for nf-core/eager 3.0 release sometime soon!\n\n\n\nOverview of the development status of nf-core/eager 3.0 as of October 2023, new functionality marked in purple."
  },
  {
    "objectID": "eager.html#how-can-i-get-help-with-problems-or-questions",
    "href": "eager.html#how-can-i-get-help-with-problems-or-questions",
    "title": "4  Introduction to nf-core/eager",
    "section": "4.7 How can I get help with problems or questions?",
    "text": "4.7 How can I get help with problems or questions?\nCheck the website for in-depth documentation of nf-core/eager.\n Raise your issue on GitHub.\nJoin the #eager channel on the nf-core Slack."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ewels, Philip A., Alexander Peltzer, Sven Fillinger, Harshil Patel,\nJohannes Alneberg, Andreas Wilm, Maxime Ulysse Garcia, Paolo Di Tommaso,\nand Sven Nahnsen. 2020. “The Nf-Core Framework for\nCommunity-Curated Bioinformatics Pipelines.” Nature\nBiotechnology 38 (3): 276–78. https://doi.org/10.1038/s41587-020-0439-x.\n\n\nFellows Yates, James A., Thiseas C. Lamnidis, Maxime Borry, Aida\nAndrades Valtueña, Zandra Fagernäs, Stephen Clayton, Maxime U. Garcia,\nJudith Neukamm, and Alexander Peltzer. 2021. “Reproducible,\nPortable, and Efficient Ancient Genome Reconstruction with\nNf-Core/Eager.” PeerJ 9 (March): e10947. https://doi.org/10.7717/peerj.10947.\n\n\nGreen, Richard E, Johannes Krause, Adrian W Briggs, Tomislav Maricic,\nUdo Stenzel, Martin Kircher, Nick Patterson, et al. 2010. “A Draft\nSequence of the Neandertal Genome.” Science 328 (5979):\n710–22. http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed&id=20448178&retmode=ref&cmd=prlinks.\n\n\nLamnidis, Thiseas C, Kerttu Majander, Choongwon Jeong, Elina Salmela,\nAnna Wessman, Vyacheslav Moiseyev, Valery Khartanovich, et al. 2018.\n“Ancient Fennoscandian Genomes Reveal Origin and Spread of\nSiberian Ancestry in Europe.” Nature Communications 9\n(1): 5018. https://doi.org/10.1038/s41467-018-07483-5.\n\n\nMallick, Swapan, Adam Micco, Matthew Mah, Harald Ringbauer, Iosif\nLazaridis, Iñigo Olalde, Nick Patterson, and David Reich. 2023.\n“The Allen Ancient DNA Resource (AADR):\nA Curated Compendium of Ancient Human Genomes,” April. https://doi.org/10.1101/2023.04.06.535797.\n\n\nMartin, Simon H, John W Davey, and Chris D Jiggins. 2015.\n“Evaluating the Use of ABBA-BABA Statistics to Locate\nIntrogressed Loci.” Molecular Biology and Evolution 32\n(1): 244–57. https://doi.org/10.1093/molbev/msu269.\n\n\nPatterson, Nick, Priya Moorjani, Yontao Luo, Swapan Mallick, Nadin\nRohland, Yiping Zhan, Teri Genschoreck, Teresa Webster, and David Reich.\n2012. “Ancient Admixture in Human History.”\nGenetics 192 (3): 1065–93. https://doi.org/10.1534/genetics.112.145037.\n\n\nPeter, Benjamin M. 2016. “Admixture, Population Structure, and\nF-Statistics.” Genetics 202 (4): 1485–1501.\nhttps://doi.org/10.1534/genetics.115.183913.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg,\nGabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al.\n2016. “The FAIR Guiding Principles for Scientific\nData Management and Stewardship.” Scientific Data 3 (1).\nhttps://doi.org/10.1038/sdata.2016.18."
  },
  {
    "objectID": "fst.html",
    "href": "fst.html",
    "title": "5  Measuring population structure using Fst",
    "section": "",
    "text": "\\(F_\\text{ST}\\) is a measure for how differentiated two populations are, taking into account internal genetic variation. It sometimes called the “Fixation Index”. It is in spirit very similar to \\(F_2\\), in that it becomes 0 if two populations are not differentiated at all (meaning they are effectively the same), and the more differentiated, the more positive is the measure. However, \\(F_\\text{ST}\\) is scaled very differently from \\(F_2\\). While both statistics range mathematically from 0 to 1, the upper bound 1 has very different meanings in both. A theoretical value of \\(F_2=1\\) would mean that both populations are fixed at different alleles in all studied SNPs, which is practically not possible (even completely random fixations would suggest that 1/4 of them would agree given that there are only four nucleotides, let alone the fact that such deeply diverged populations/species would not be alignable anymore). One can say that the time-scale on which \\(F_2\\) approaches 1 is the time scale of nucleotide substitutions (i.e. mutations plus fixation) along species branches, which in neutral evolution is given by the inverse mutation rate \\(1/\\mu\\). This would mean something on the order of \\(10^8\\) generations, which is arguably as deep as the tree of live itself. In contrast, \\(F_\\text{ST}\\) approaches 1 on the time-scale of fixation of standing variation, which is \\(2N\\) generations, which for humans is on the order of 10000 generations, so around the depth of modern-human diversity from its origins in Africa several hundred thousand years ago. Arguably, this time scale is much more useful for data analyses and thus easier to interpret.\nWhile there are various mathematical definitions for both the theoretical definition and estimation for \\(F_\\text{ST}\\), which differ in subtle ways, we here follow the excellent paper by (Bhatia et al. 2013), which proposes the following estimator, termed Hudson-estimator:\n\\[F_\\text{ST}=1-\\frac{H_w}{H_b}\\]\nHere, \\(H_w\\) is the average heterozygosity within each population, and \\(H_b\\) is the average heterozygosity between two populations. We can easily read off the two boundaries of the definition: At the lower end, we have \\(F_\\text{ST}=0\\) if and only if \\(H_w=H_b\\), so there is no difference between heterozygosity measured within or between groups, which is equivalent to saying that the two populations are the same. On the upper end we have \\(F_\\text{ST}=1\\) if and only if \\(H_w=0\\), so all observed variants are fully fixed in both populations (but not necessarily different between the populations).\n\n\n\n\n\n\nNote\n\n\n\n(Bhatia et al. 2013) also give a more formal evolutionary definition of \\(F_\\text{ST}\\), developed in turn by (Weir and Hill 2002), in terms of covariance between derived and ancestral populations. Specifically, for a given SNP, the definition involves the conditional probability of allele frequency \\(p_i\\) in population \\(i\\), given an ancestral allele frequency \\(p_\\text{anc}\\), which is defined as a random process with the expectation\n\nWeir, B S, and W G Hill. 2002. “Estimating f-Statistics.” Annual Review of Genetics 36: 721–50. https://doi.org/10.1146/annurev.genet.36.050802.093940.\n\\[E(p_i|p_\\text{anc}) = p_\\text{anc}\\]\nand variance \\[Var(p_i|p_\\text{anc}) = F_\\text{ST}^i p_\\text{anc}(1-p_\\text{anc}).\\]\nThis form of the conditional variance can be understood by analysing the equation for the two boundary cases: For \\(F_\\text{ST}^i=0\\), there is no variance, so the conditional probability of the derived frequency will be completely determined by the ancestral frequency with no random change. In contrast \\(F_\\text{ST}^i=1\\) means that the variance in the derived allele frequency is that of a binomial distribution with variance \\(p_\\text{anc}(1-p_\\text{anc}\\), indicating random but complete fixation of the frequency to 0 or 1.\n\\(F_\\text{ST}\\) between two populations A and B is then defined as \\[F_\\text{ST}(A,B) = \\frac{F_\\text{ST}^A+F_\\text{ST}^B}{2}\\],\nso the average of the two drift processes.\n\n\n(Bhatia et al. 2013) show that the Hudson-estimator above can be recast as\n\nBhatia, G, N Patterson, S Sankararaman, and A L Price. 2013. “Estimating and Interpreting FST: The Impact of Rare Variants.” Genome Research 23 (9): 1514–21. http://genome.cshlp.org/cgi/doi/10.1101/gr.154831.113.\n\\[F_\\text{ST}(A,B)=\\frac{(a-b)^2}{a(1-b)+b(1-a)}\\]\nHere, \\(a\\) and \\(b\\) denote population allele frequencies, which are in principle unobserved, but can be approximated by sample allele frequencies. This approximation is biased, and (Patterson et al. 2012) gives additional formulae for an (asympotically) unbiased estimator.\nFrom this definition, you can see that \\(F_\\text{ST}(A,B)\\) is closely related to F2-statistics, introduced in (Patterson et al. 2012):\n\\[F_2(A,B)=(a-b)^2\\].\nIn some sense, \\(F_\\text{ST}(A,B)\\) can be considered a normalised version of \\(F_2(A,B)\\).\nIf you’ve gone through our chapter on F3 and F4 statistics, you will have already encountered our software xerxes. You can compute both the biased and the approximately unbiased estimators for \\(F_\\text{ST}(A,B)\\), using the FST or FSTvanilla statistics, as defined in the whitepaper.\nFor what follows, we will use the approximately unbiased form FST.\n\\(F_\\text{ST}(A,B)\\) has a convenient and untuitive scale: It ranges from 0 to 1, where \\(F_\\text{ST}(A,B)=0\\) denotes that \\(A\\) and \\(B\\) are the same population, with no differentiation whatsoever. On the other hand of the spectrum we have \\(F_\\text{ST}(A,B)=1\\), which would mean that two populations are fully separated.\nAnother way to see this measure is to consider it as relative shared variance: If you consider genetic variation between \\(A\\) and \\(B\\), and within each of \\(A\\) and \\(B\\), then \\(F_\\text{ST}(A,B)\\) can be considered to measure the average variance between populations relative to the average variance within populations, again with intuitive boundaries 0 and 1."
  },
  {
    "objectID": "fst.html#section",
    "href": "fst.html#section",
    "title": "5  Measuring population structure using Fst",
    "section": "5.1 ",
    "text": "5.1 \nFor human present-day populations, we can compute pairwise FSt using xerxes."
  },
  {
    "objectID": "fst.html#computing-fst-using-xerxes",
    "href": "fst.html#computing-fst-using-xerxes",
    "title": "5  Measuring population structure using Fst",
    "section": "5.2 Computing FST using xerxes",
    "text": "5.2 Computing FST using xerxes\nFor human present-day populations, we can compute pairwise FSt using xerxes.\nWe here chose a number of populations from (Patterson et al. 2012) with more than 10 samples per population, and prepare the following config file for xerxes:\n\nPatterson, Nick, Priya Moorjani, Yontao Luo, Swapan Mallick, Nadin Rohland, Yiping Zhan, Teri Genschoreck, Teresa Webster, and David Reich. 2012. “Ancient Admixture in Human History.” Genetics 192 (3): 1065–93. https://doi.org/10.1534/genetics.112.145037.\nfstats:\n- type: FST\n  a: [\"Adygei\", \"Balochi\", \"Basque\", \"BedouinA\", \"BedouinB\", \"Biaka\", \"Brahui\", \"Burusho\", \"Druze\", \"French\", \"Han\", \"Hazara\", \"Italian_North\", \"Japanese\", \"Kalash\", \"Karitiana\", \"Makrani\", \"Mandenka\", \"Mayan\", \"Mozabite\", \"Orcadian\", \"Palestinian\", \"Papuan\", \"Pathan\", \"Pima\", \"Russian\", \"Sardinian\", \"Sindhi_Pakistan\", \"Yakut\", \"Yoruba\"]\n  b: [\"Adygei\", \"Balochi\", \"Basque\", \"BedouinA\", \"BedouinB\", \"Biaka\", \"Brahui\", \"Burusho\", \"Druze\", \"French\", \"Han\", \"Hazara\", \"Italian_North\", \"Japanese\", \"Kalash\", \"Karitiana\", \"Makrani\", \"Mandenka\", \"Mayan\", \"Mozabite\", \"Orcadian\", \"Palestinian\", \"Papuan\", \"Pathan\", \"Pima\", \"Russian\", \"Sardinian\", \"Sindhi_Pakistan\", \"Yakut\", \"Yoruba\"]\n- type: F2\n  a: [\"Adygei\", \"Balochi\", \"Basque\", \"BedouinA\", \"BedouinB\", \"Biaka\", \"Brahui\", \"Burusho\", \"Druze\", \"French\", \"Han\", \"Hazara\", \"Italian_North\", \"Japanese\", \"Kalash\", \"Karitiana\", \"Makrani\", \"Mandenka\", \"Mayan\", \"Mozabite\", \"Orcadian\", \"Palestinian\", \"Papuan\", \"Pathan\", \"Pima\", \"Russian\", \"Sardinian\", \"Sindhi_Pakistan\", \"Yakut\", \"Yoruba\"]\n  b: [\"Adygei\", \"Balochi\", \"Basque\", \"BedouinA\", \"BedouinB\", \"Biaka\", \"Brahui\", \"Burusho\", \"Druze\", \"French\", \"Han\", \"Hazara\", \"Italian_North\", \"Japanese\", \"Kalash\", \"Karitiana\", \"Makrani\", \"Mandenka\", \"Mayan\", \"Mozabite\", \"Orcadian\", \"Palestinian\", \"Papuan\", \"Pathan\", \"Pima\", \"Russian\", \"Sardinian\", \"Sindhi_Pakistan\", \"Yakut\", \"Yoruba\"]\nThis will then produce all combinations of \\(FST(A, B)\\) and \\(F_2(A, B)\\) as indicated in the population lists.\n\n\n\n\n\n\nNote\n\n\n\nNote that the config-file engine in xerxes always computes all the combinations of populations, even for cases of \\(A=B\\). It also doesn’t know about symmetry, so will happily compute the redundant statistics \\(FST(\\text{Adygei}, \\text{Balochi})\\) and \\(FST(\\text{Adygei}, \\text{Balochi})\\). While this could be possibly improved, there is no big harm done, as this runs fairly quickly.\n\n\nWe run this config file using the command line\nREPO=/path/to/community-archive/2012_PattersonGenetics\n\nxerxes fstats -d $REPO --statConfig fstat_world_config.yaml -f fstat_world_output.tsv > fstat_world_table.txt\nThe standard output, is a nicely layouted ASCII Table, which looks like this in the beginning:\n.-----------.-----------------.-----------------.---.---.---------.----------------.--------------------.------------------.---------------------.\n| Statistic |        a        |        b        | c | d | NrSites | Estimate_Total | Estimate_Jackknife | StdErr_Jackknife |  Z_score_Jackknife  |\n:===========:=================:=================:===:===:=========:================:====================:==================:=====================:\n| FST       | Adygei          | Adygei          |   |   | 409606  | -3.2363e-2     | -3.2363e-2         | 1.1079e-6        | -29211.78654425142  |\n| FST       | Adygei          | Balochi         |   |   | 439484  | 1.0183e-2      | 1.0183e-2          | 2.6463e-4        | 38.47836213081687   |\n| FST       | Adygei          | Basque          |   |   | 429795  | 1.5041e-2      | 1.5041e-2          | 3.0579e-4        | 49.18650753804277   |\n| FST       | Adygei          | BedouinA        |   |   | 464801  | 1.1125e-2      | 1.1125e-2          | 2.3306e-4        | 47.733496037556684  |\n| FST       | Adygei          | BedouinB        |   |   | 442878  | 2.6486e-2      | 2.6486e-2          | 4.2233e-4        | 62.71408519081527   |\n| FST       | Adygei          | Biaka           |   |   | 511741  | 0.1241         | 0.1241             | 7.2278e-4        | 171.63603135734155  |\n| FST       | Adygei          | Brahui          |   |   | 439939  | 1.1874e-2      | 1.1874e-2          | 2.6634e-4        | 44.580717401262476  |\n| FST       | Adygei          | Burusho         |   |   | 439428  | 1.5395e-2      | 1.5395e-2          | 2.9055e-4        | 52.98665735172525   |\n| FST       | Adygei          | Druze           |   |   | 448233  | 1.0339e-2      | 1.0339e-2          | 1.9614e-4        | 52.709862042633105  |\n| FST       | Adygei          | French          |   |   | 435238  | 7.7213e-3      | 7.7213e-3          | 2.4507e-4        | 31.506092803895292  |\n| FST       | Adygei          | Han             |   |   | 442553  | 7.7084e-2      | 7.7084e-2          | 7.5943e-4        | 101.5019381212137   |\nbut of course has many more lines (>1800 in this case). We also used the -f flag to output a tab-separated file, here named fstat_world_output.tsv, which is easier to read into R."
  }
]